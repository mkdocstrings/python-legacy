{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"mkdocstrings-python (legacy) \u00a4 A legacy Python handler for mkdocstrings. Requirements \u00a4 mkdocstrings-python (legacy) requires Python 3.7 or above. To install Python 3.7, I recommend using pyenv . # install pyenv git clone https://github.com/pyenv/pyenv ~/.pyenv # setup pyenv (you should also put these three lines in .bashrc or similar) export PATH = \" ${ HOME } /.pyenv/bin: ${ PATH } \" export PYENV_ROOT = \" ${ HOME } /.pyenv\" eval \" $( pyenv init - ) \" # install Python 3.7 pyenv install 3 .7.12 # make it available globally pyenv global system 3 .7.12 Installation \u00a4 With pip : pip install mkdocstrings-python-legacy With pipx : python3.7 -m pip install --user pipx pipx install mkdocstrings-python-legacy","title":"Overview"},{"location":"#mkdocstrings-python-legacy","text":"A legacy Python handler for mkdocstrings.","title":"mkdocstrings-python (legacy)"},{"location":"#requirements","text":"mkdocstrings-python (legacy) requires Python 3.7 or above. To install Python 3.7, I recommend using pyenv . # install pyenv git clone https://github.com/pyenv/pyenv ~/.pyenv # setup pyenv (you should also put these three lines in .bashrc or similar) export PATH = \" ${ HOME } /.pyenv/bin: ${ PATH } \" export PYENV_ROOT = \" ${ HOME } /.pyenv\" eval \" $( pyenv init - ) \" # install Python 3.7 pyenv install 3 .7.12 # make it available globally pyenv global system 3 .7.12","title":"Requirements"},{"location":"#installation","text":"With pip : pip install mkdocstrings-python-legacy With pipx : python3.7 -m pip install --user pipx pipx install mkdocstrings-python-legacy","title":"Installation"},{"location":"changelog/","text":"Changelog \u00a4 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . 0.2.2 - 2022-02-19 \u00a4 Compare with 0.2.1 Bug Fixes \u00a4 Handle empty error in JSON output ( 0e7ab59 by rachmadani haryono). PR #1 0.2.1 - 2022-02-05 \u00a4 Compare with 0.2.0 Dependencies \u00a4 Require at least mkdocstrings 0.18 ( 09d8e9c by Timoth\u00e9e Mazzucotelli). 0.2.0 - 2022-02-03 \u00a4 Compare with 0.1.0 Features \u00a4 Add show_signature rendering option ( e741b37 by Will Da Silva). Dependencies \u00a4 Depend on mkdocstrings ( a154c05 by Timoth\u00e9e Mazzucotelli). Code Refactoring \u00a4 Add user warning about mkdocstrings extra ( 71ea2d8 by Timoth\u00e9e Mazzucotelli). 0.1.0 - 2021-12-18 \u00a4 Compare with first commit Features \u00a4 Copy code from mkdocstrings ( 720f91e by Timoth\u00e9e Mazzucotelli).","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#022-2022-02-19","text":"Compare with 0.2.1","title":"0.2.2 - 2022-02-19"},{"location":"changelog/#bug-fixes","text":"Handle empty error in JSON output ( 0e7ab59 by rachmadani haryono). PR #1","title":"Bug Fixes"},{"location":"changelog/#021-2022-02-05","text":"Compare with 0.2.0","title":"0.2.1 - 2022-02-05"},{"location":"changelog/#dependencies","text":"Require at least mkdocstrings 0.18 ( 09d8e9c by Timoth\u00e9e Mazzucotelli).","title":"Dependencies"},{"location":"changelog/#020-2022-02-03","text":"Compare with 0.1.0","title":"0.2.0 - 2022-02-03"},{"location":"changelog/#features","text":"Add show_signature rendering option ( e741b37 by Will Da Silva).","title":"Features"},{"location":"changelog/#dependencies_1","text":"Depend on mkdocstrings ( a154c05 by Timoth\u00e9e Mazzucotelli).","title":"Dependencies"},{"location":"changelog/#code-refactoring","text":"Add user warning about mkdocstrings extra ( 71ea2d8 by Timoth\u00e9e Mazzucotelli).","title":"Code Refactoring"},{"location":"changelog/#010-2021-12-18","text":"Compare with first commit","title":"0.1.0 - 2021-12-18"},{"location":"changelog/#features_1","text":"Copy code from mkdocstrings ( 720f91e by Timoth\u00e9e Mazzucotelli).","title":"Features"},{"location":"code_of_conduct/","text":"Contributor Covenant Code of Conduct \u00a4 Our Pledge \u00a4 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00a4 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00a4 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00a4 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00a4 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at pawamoy@pm.me . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00a4 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4","title":"Code of Conduct"},{"location":"code_of_conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"code_of_conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at pawamoy@pm.me . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4","title":"Attribution"},{"location":"contributing/","text":"Contributing \u00a4 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Environment setup \u00a4 Nothing easier! Fork and clone the repository, then: cd python-legacy make setup Note If it fails for some reason, you'll need to install PDM manually. You can install it with: python3 -m pip install --user pipx pipx install pdm Now you can try running make setup again, or simply pdm install . You now have the dependencies installed. Run make help to see all the available actions! Tasks \u00a4 This project uses duty to run tasks. A Makefile is also provided. The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you can do one of the following: export PYTHON_VERSIONS= : this will run the task with only the current Python version run the task directly with pdm run duty TASK The Makefile detects if a virtual environment is activated, so make will work the same with the virtualenv activated or not. Development \u00a4 As usual: create a new branch: git checkout -b feature-or-bugfix-name edit the code and/or the documentation If you updated the documentation or the project dependencies: run make docs-regen run make docs-serve , go to http://localhost:8000 and check that everything looks good Before committing: run make format to auto-format the code run make check to check everything (fix any warning) run make test to run the tests (fix any issue) follow our commit message convention If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review. Don't bother updating the changelog, we will take care of this. Commit message convention \u00a4 Commits messages must follow the Angular style : <type>[(scope)]: Subject [Body] Scope and body are optional. Type can be: build : About packaging, building wheels, etc. chore : About packaging or repo/files management. ci : About Continuous Integration. docs : About documentation. feat : New feature. fix : Bug fix. perf : About performance. refactor : Changes which are not features nor bug fixes. style : A change in code style/format. tests : About tests. Subject (and body) must be valid Markdown. If you write a body, please add issues references at the end: Body. References: #10, #11. Fixes #15. Pull requests guidelines \u00a4 Link to any related issue in the Pull Request message. During review, we recommend using fixups: # SHA is the SHA of the commit you want to fix git commit --fixup = SHA Once all the changes are approved, you can squash your commits: git rebase -i --autosquash master And force-push: git push -f If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.","title":"Contributing"},{"location":"contributing/#environment-setup","text":"Nothing easier! Fork and clone the repository, then: cd python-legacy make setup Note If it fails for some reason, you'll need to install PDM manually. You can install it with: python3 -m pip install --user pipx pipx install pdm Now you can try running make setup again, or simply pdm install . You now have the dependencies installed. Run make help to see all the available actions!","title":"Environment setup"},{"location":"contributing/#tasks","text":"This project uses duty to run tasks. A Makefile is also provided. The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you can do one of the following: export PYTHON_VERSIONS= : this will run the task with only the current Python version run the task directly with pdm run duty TASK The Makefile detects if a virtual environment is activated, so make will work the same with the virtualenv activated or not.","title":"Tasks"},{"location":"contributing/#development","text":"As usual: create a new branch: git checkout -b feature-or-bugfix-name edit the code and/or the documentation If you updated the documentation or the project dependencies: run make docs-regen run make docs-serve , go to http://localhost:8000 and check that everything looks good Before committing: run make format to auto-format the code run make check to check everything (fix any warning) run make test to run the tests (fix any issue) follow our commit message convention If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review. Don't bother updating the changelog, we will take care of this.","title":"Development"},{"location":"contributing/#commit-message-convention","text":"Commits messages must follow the Angular style : <type>[(scope)]: Subject [Body] Scope and body are optional. Type can be: build : About packaging, building wheels, etc. chore : About packaging or repo/files management. ci : About Continuous Integration. docs : About documentation. feat : New feature. fix : Bug fix. perf : About performance. refactor : Changes which are not features nor bug fixes. style : A change in code style/format. tests : About tests. Subject (and body) must be valid Markdown. If you write a body, please add issues references at the end: Body. References: #10, #11. Fixes #15.","title":"Commit message convention"},{"location":"contributing/#pull-requests-guidelines","text":"Link to any related issue in the Pull Request message. During review, we recommend using fixups: # SHA is the SHA of the commit you want to fix git commit --fixup = SHA Once all the changes are approved, you can squash your commits: git rebase -i --autosquash master And force-push: git push -f If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.","title":"Pull requests guidelines"},{"location":"credits/","text":"Credits \u00a4 These projects were used to build mkdocstrings-python-legacy . Thank you! python | pdm | copier-pdm Direct dependencies \u00a4 autoflake | black | darglint | duty | flake8-bandit | flake8-black | flake8-bugbear | flake8-builtins | flake8-comprehensions | flake8-docstrings | flake8-pytest-style | flake8-string-format | flake8-tidy-imports | flake8-variables-names | git-changelog | isort | mkdocs | mkdocs-coverage | mkdocs-gen-files | mkdocs-literate-nav | mkdocs-material | mkdocs-section-index | mkdocstrings | mypy | pep8-naming | pytest | pytest-cov | pytest-randomly | pytest-sugar | pytest-xdist | pytkdocs | safety | toml | types-markdown | types-toml | wps-light Indirect dependencies \u00a4 ansimarkup | astor | astunparse | atomicwrites | attrs | bandit | cached-property | certifi | charset-normalizer | click | colorama | coverage | dparse | execnet | failprint | flake8 | flake8-plugin-utils | flake8-polyfill | ghp-import | gitdb | gitpython | idna | importlib-metadata | iniconfig | jinja2 | markdown | markupsafe | mccabe | mergedeep | mkdocs-autorefs | mkdocs-material-extensions | mkdocstrings-python-legacy | mypy-extensions | packaging | pathspec | pbr | platformdirs | pluggy | ptyprocess | py | pycodestyle | pydocstyle | pyflakes | pygments | pymdown-extensions | pyparsing | pytest-forked | python-dateutil | pyyaml | pyyaml-env-tag | requests | semver | setuptools | six | smmap | snowballstemmer | stevedore | termcolor | tomli | typed-ast | typing-extensions | urllib3 | watchdog | wheel | zipp More credits from the author","title":"Credits"},{"location":"credits/#credits","text":"These projects were used to build mkdocstrings-python-legacy . Thank you! python | pdm | copier-pdm","title":"Credits"},{"location":"credits/#direct-dependencies","text":"autoflake | black | darglint | duty | flake8-bandit | flake8-black | flake8-bugbear | flake8-builtins | flake8-comprehensions | flake8-docstrings | flake8-pytest-style | flake8-string-format | flake8-tidy-imports | flake8-variables-names | git-changelog | isort | mkdocs | mkdocs-coverage | mkdocs-gen-files | mkdocs-literate-nav | mkdocs-material | mkdocs-section-index | mkdocstrings | mypy | pep8-naming | pytest | pytest-cov | pytest-randomly | pytest-sugar | pytest-xdist | pytkdocs | safety | toml | types-markdown | types-toml | wps-light","title":"Direct dependencies"},{"location":"credits/#indirect-dependencies","text":"ansimarkup | astor | astunparse | atomicwrites | attrs | bandit | cached-property | certifi | charset-normalizer | click | colorama | coverage | dparse | execnet | failprint | flake8 | flake8-plugin-utils | flake8-polyfill | ghp-import | gitdb | gitpython | idna | importlib-metadata | iniconfig | jinja2 | markdown | markupsafe | mccabe | mergedeep | mkdocs-autorefs | mkdocs-material-extensions | mkdocstrings-python-legacy | mypy-extensions | packaging | pathspec | pbr | platformdirs | pluggy | ptyprocess | py | pycodestyle | pydocstyle | pyflakes | pygments | pymdown-extensions | pyparsing | pytest-forked | python-dateutil | pyyaml | pyyaml-env-tag | requests | semver | setuptools | six | smmap | snowballstemmer | stevedore | termcolor | tomli | typed-ast | typing-extensions | urllib3 | watchdog | wheel | zipp More credits from the author","title":"Indirect dependencies"},{"location":"license/","text":"ISC License Copyright (c) 2021, Timoth\u00e9e Mazzucotelli Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.","title":"License"},{"location":"usage/","text":"This is the documentation for the LEGACY Python handler. To read the documentation for the NEW, EXPERIMENTAL handler, go to the new handler documentation . Handler options \u00a4 Like every handler, the Python handler accepts the common selection and rendering options, both as global and local options. The selection options gives you control over the selection of Python objects, while the rendering options lets you change how the documentation is rendered. It also accepts these additional global-only options: Option Type Description Default setup_commands list of str Run these commands before starting the documentation collection. [] Example: setup Django before collecting documentation # mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import os - import django - os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"my_django_app.settings\") - django.setup() Important Additional options like setup_commands are used only once, when instantiating the handler the first time it is requested. This is why they are considered global-only options, as they will have no effect if used as local options. Selection \u00a4 The following options are directly passed to the handler's collector. See Collector: pytkdocs to learn more about pytkdocs . Option Type Description Default filters list of str List of filtering regular expressions. Prefix with ! to exclude objects whose name match. The default means exclude private members . [\"!^_[^_]\"] members bool , or list of str Explicitly select members. True means all , false means none . True inherited_members bool Also select members inherited from parent classes. False docstring_style str Docstring style to parse. pytkdocs supports google , numpy and restructured-text . Note: Numpy-style requires the numpy-style extra of pytkdocs . \"google\" docstring_options dict Options to pass to the docstring parser. See Collector: pytkdocs {} new_path_syntax bool Whether to use the new \"colon\" path syntax when importing objects. False Configuration example Global Local # mkdocs.yml plugins : - mkdocstrings : handlers : python : selection : filters : - \"!^_\" # exlude all members starting with _ - \"^__init__$\" # but always include __init__ modules and methods :: : my_package selection : filters : [] # pick up everything Rendering \u00a4 The default rendering options. Option Type Description Default show_root_heading bool Show the heading of the object at the root of the documentation tree. False show_root_toc_entry bool If the root heading is not shown, at least add a ToC entry for it. True show_root_full_path bool Show the full Python path for the root object heading. True show_object_full_path bool Show the full Python path of every object. False show_root_members_full_path bool Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, show_object_full_path overrides. False show_category_heading bool When grouped by categories, show a heading for each category. False show_if_no_docstring bool Show the object heading even if it has no docstring or children with docstrings. False show_signature bool Show method and function signatures. True show_signature_annotations bool Show the type annotations in method and function signatures. False show_source bool Show the source code of this object. True show_bases bool Show the base classes of a class. True group_by_category bool Group the object's children by categories: attributes, classes, functions, methods, and modules. True heading_level int The initial heading level to use. 2 members_order str The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. alphabetical These options affect how the documentation is rendered. Configuration example Global Local # mkdocs.yml plugins : - mkdocstrings : handlers : python : rendering : show_root_heading : yes ## `ClassA` ::: my_package.my_module.ClassA rendering: show_root_heading: no heading_level: 3 Collector: pytkdocs \u00a4 The tool used by the Python handler to collect documentation from Python source code is pytkdocs . It stands for (Python) Take Docs , and is supposed to be a pun on MkDocs ( Make Docs ?). Supported docstrings styles \u00a4 Right now, pytkdocs supports the Google-style, Numpy-style and reStructuredText-style docstring formats. The style used by default is the Google-style. You can configure what style you want to use with the docstring_style and docstring_options selection options , both globally or per autodoc instruction. Google-style \u00a4 You can see examples of Google-style docstrings in Napoleon's documentation . Sections \u00a4 Docstrings sections are parsed by pytkdocs and rendered by mkdocstrings . Supported sections are: Arguments (or Args , Parameters , Params ) Attributes Examples (or Example ) Raises (or Raise , Except , Exceptions ) Returns (or Return ) Admonitions \u00a4 Additionally, any section that is not recognized will be transformed into its admonition equivalent. For example: Original Modified Result \"\"\" Note: You can disable this behavior with the `replace_admonitions` option. To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" \"\"\" !!! note \"You can disable this behavior with the `replace_admonitions` option.\" To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" You can disable this behavior with the replace_admonitions parser option. To prevent pytkdocs from converting sections to admonitions, use the replace_admonitions parser option: ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no So meta! As shown in the above example, this can be disabled with the replace_admonitions option of the Google-style parser: :: : my_package.my_module selection : docstring_style : google # this is the default docstring_options : replace_admonitions : no Annotations \u00a4 Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Parameters: Name Type Description Default param1 int An integer? required param2 Optional[str] A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! None Source code in snippets/function_annotations_google.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Arguments: param1: An integer? param2: A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! \"\"\" return f \" { param2 }{ param1 } \" Numpy-style \u00a4 Extra dependency required You'll need an extra dependency to parse Numpy-style docstrings: pdm add -d --group docs 'pytkdocs[numpy-style]' poetry add -D 'pytkdocs[numpy-style]' pip install 'pytkdocs[numpy-style]' # etc. Note As Numpy-style is partially supported by the underlying parser, you may experience problems in the building process if your docstring has a Methods section in the class docstring (see #366 ). You can see examples of Numpy-style docstrings in numpydoc's documentation . reStructuredText-style \u00a4 Partial support Only RST- style is supported, not the whole RST markup specification. Docstrings will still be converted as Markdown. You can see examples of reStructuredText-style docstrings in Sphinx's documentation . Sections \u00a4 Docstrings directives are parsed by pytkdocs and rendered by mkdocstrings . Supported directives are: param (or parameter , arg , argument , key , keyword ) type raises (or raise , except , exception ) var (or ivar , cvar ) vartype returns (or return1 ) rtype Details about how to use each directive can be found in the Sphinx domain documentation Annotations \u00a4 Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Complex markup is supported in the main description section. I'm a code block! Parameters: Name Type Description Default param1 int An integer? required param2 Optional[str] A string? If you have a long description, you can split it on multiple lines. None Source code in snippets/function_annotations_rst.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Complex markup is supported in the main description section. I'm a code block! :param param1: An integer? :param param2: A string? If you have a long description, you can split it on multiple lines. \"\"\" return f \" { param2 }{ param1 } \" Finding modules \u00a4 In order for pytkdocs to find your packages and modules, you should take advantage of the usual Python loading mechanisms: install your package in the current virtualenv: . venv/bin/activate pip install -e . poetry install ...etc. or add your package(s) parent directory in the PYTHONPATH . ( The following instructions assume your Python package is in the src directory. ) In Bash and other shells, you can run your command like this (note the prepended PYTHONPATH=... ): PYTHONPATH = src poetry run mkdocs serve You could also export that variable, but this is not recommended as it could affect other Python processes: export PYTHONPATH = src # Linux/Bash and similar setx PYTHONPATH src # Windows, USE AT YOUR OWN RISKS You can also use the Python handler setup_commands : # mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - sys.path.append(\"src\") # or sys.path.insert(0, \"src\") Mocking libraries \u00a4 You may want to to generate documentation for a package while its dependencies are not available. The Python handler provides itself no builtin way to mock libraries, but you can use the setup_commands to mock them manually: mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - from unittest.mock import MagicMock as mock - sys.modules[\"lib1\"] = mock() - sys.modules[\"lib2\"] = mock() - sys.modules[\"lib2.module1\"] = mock() - sys.modules[\"lib2.module1.moduleB\"] = mock() # etc Recommended style (Material) \u00a4 Here are some CSS rules for the Material for MkDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : 4 px solid rgba ( 230 , 230 , 230 ); margin-bottom : 80 px ; } Recommended style (ReadTheDocs) \u00a4 Here are some CSS rules for the built-in ReadTheDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : 4 px solid rgba ( 230 , 230 , 230 ); margin-bottom : 60 px ; }","title":"Usage"},{"location":"usage/#handler-options","text":"Like every handler, the Python handler accepts the common selection and rendering options, both as global and local options. The selection options gives you control over the selection of Python objects, while the rendering options lets you change how the documentation is rendered. It also accepts these additional global-only options: Option Type Description Default setup_commands list of str Run these commands before starting the documentation collection. [] Example: setup Django before collecting documentation # mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import os - import django - os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"my_django_app.settings\") - django.setup() Important Additional options like setup_commands are used only once, when instantiating the handler the first time it is requested. This is why they are considered global-only options, as they will have no effect if used as local options.","title":"Handler options"},{"location":"usage/#selection","text":"The following options are directly passed to the handler's collector. See Collector: pytkdocs to learn more about pytkdocs . Option Type Description Default filters list of str List of filtering regular expressions. Prefix with ! to exclude objects whose name match. The default means exclude private members . [\"!^_[^_]\"] members bool , or list of str Explicitly select members. True means all , false means none . True inherited_members bool Also select members inherited from parent classes. False docstring_style str Docstring style to parse. pytkdocs supports google , numpy and restructured-text . Note: Numpy-style requires the numpy-style extra of pytkdocs . \"google\" docstring_options dict Options to pass to the docstring parser. See Collector: pytkdocs {} new_path_syntax bool Whether to use the new \"colon\" path syntax when importing objects. False Configuration example Global Local # mkdocs.yml plugins : - mkdocstrings : handlers : python : selection : filters : - \"!^_\" # exlude all members starting with _ - \"^__init__$\" # but always include __init__ modules and methods :: : my_package selection : filters : [] # pick up everything","title":"Selection"},{"location":"usage/#rendering","text":"The default rendering options. Option Type Description Default show_root_heading bool Show the heading of the object at the root of the documentation tree. False show_root_toc_entry bool If the root heading is not shown, at least add a ToC entry for it. True show_root_full_path bool Show the full Python path for the root object heading. True show_object_full_path bool Show the full Python path of every object. False show_root_members_full_path bool Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, show_object_full_path overrides. False show_category_heading bool When grouped by categories, show a heading for each category. False show_if_no_docstring bool Show the object heading even if it has no docstring or children with docstrings. False show_signature bool Show method and function signatures. True show_signature_annotations bool Show the type annotations in method and function signatures. False show_source bool Show the source code of this object. True show_bases bool Show the base classes of a class. True group_by_category bool Group the object's children by categories: attributes, classes, functions, methods, and modules. True heading_level int The initial heading level to use. 2 members_order str The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. alphabetical These options affect how the documentation is rendered. Configuration example Global Local # mkdocs.yml plugins : - mkdocstrings : handlers : python : rendering : show_root_heading : yes ## `ClassA` ::: my_package.my_module.ClassA rendering: show_root_heading: no heading_level: 3","title":"Rendering"},{"location":"usage/#collector-pytkdocs","text":"The tool used by the Python handler to collect documentation from Python source code is pytkdocs . It stands for (Python) Take Docs , and is supposed to be a pun on MkDocs ( Make Docs ?).","title":"Collector: pytkdocs"},{"location":"usage/#supported-docstrings-styles","text":"Right now, pytkdocs supports the Google-style, Numpy-style and reStructuredText-style docstring formats. The style used by default is the Google-style. You can configure what style you want to use with the docstring_style and docstring_options selection options , both globally or per autodoc instruction.","title":"Supported docstrings styles"},{"location":"usage/#google-style","text":"You can see examples of Google-style docstrings in Napoleon's documentation .","title":"Google-style"},{"location":"usage/#sections","text":"Docstrings sections are parsed by pytkdocs and rendered by mkdocstrings . Supported sections are: Arguments (or Args , Parameters , Params ) Attributes Examples (or Example ) Raises (or Raise , Except , Exceptions ) Returns (or Return )","title":"Sections"},{"location":"usage/#admonitions","text":"Additionally, any section that is not recognized will be transformed into its admonition equivalent. For example: Original Modified Result \"\"\" Note: You can disable this behavior with the `replace_admonitions` option. To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" \"\"\" !!! note \"You can disable this behavior with the `replace_admonitions` option.\" To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" You can disable this behavior with the replace_admonitions parser option. To prevent pytkdocs from converting sections to admonitions, use the replace_admonitions parser option: ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no So meta! As shown in the above example, this can be disabled with the replace_admonitions option of the Google-style parser: :: : my_package.my_module selection : docstring_style : google # this is the default docstring_options : replace_admonitions : no","title":"Admonitions"},{"location":"usage/#annotations","text":"Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Parameters: Name Type Description Default param1 int An integer? required param2 Optional[str] A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! None Source code in snippets/function_annotations_google.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Arguments: param1: An integer? param2: A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! \"\"\" return f \" { param2 }{ param1 } \"","title":"Annotations"},{"location":"usage/#numpy-style","text":"Extra dependency required You'll need an extra dependency to parse Numpy-style docstrings: pdm add -d --group docs 'pytkdocs[numpy-style]' poetry add -D 'pytkdocs[numpy-style]' pip install 'pytkdocs[numpy-style]' # etc. Note As Numpy-style is partially supported by the underlying parser, you may experience problems in the building process if your docstring has a Methods section in the class docstring (see #366 ). You can see examples of Numpy-style docstrings in numpydoc's documentation .","title":"Numpy-style"},{"location":"usage/#restructuredtext-style","text":"Partial support Only RST- style is supported, not the whole RST markup specification. Docstrings will still be converted as Markdown. You can see examples of reStructuredText-style docstrings in Sphinx's documentation .","title":"reStructuredText-style"},{"location":"usage/#sections_1","text":"Docstrings directives are parsed by pytkdocs and rendered by mkdocstrings . Supported directives are: param (or parameter , arg , argument , key , keyword ) type raises (or raise , except , exception ) var (or ivar , cvar ) vartype returns (or return1 ) rtype Details about how to use each directive can be found in the Sphinx domain documentation","title":"Sections"},{"location":"usage/#annotations_1","text":"Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Complex markup is supported in the main description section. I'm a code block! Parameters: Name Type Description Default param1 int An integer? required param2 Optional[str] A string? If you have a long description, you can split it on multiple lines. None Source code in snippets/function_annotations_rst.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Complex markup is supported in the main description section. I'm a code block! :param param1: An integer? :param param2: A string? If you have a long description, you can split it on multiple lines. \"\"\" return f \" { param2 }{ param1 } \"","title":"Annotations"},{"location":"usage/#finding-modules","text":"In order for pytkdocs to find your packages and modules, you should take advantage of the usual Python loading mechanisms: install your package in the current virtualenv: . venv/bin/activate pip install -e . poetry install ...etc. or add your package(s) parent directory in the PYTHONPATH . ( The following instructions assume your Python package is in the src directory. ) In Bash and other shells, you can run your command like this (note the prepended PYTHONPATH=... ): PYTHONPATH = src poetry run mkdocs serve You could also export that variable, but this is not recommended as it could affect other Python processes: export PYTHONPATH = src # Linux/Bash and similar setx PYTHONPATH src # Windows, USE AT YOUR OWN RISKS You can also use the Python handler setup_commands : # mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - sys.path.append(\"src\") # or sys.path.insert(0, \"src\")","title":"Finding modules"},{"location":"usage/#mocking-libraries","text":"You may want to to generate documentation for a package while its dependencies are not available. The Python handler provides itself no builtin way to mock libraries, but you can use the setup_commands to mock them manually: mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - from unittest.mock import MagicMock as mock - sys.modules[\"lib1\"] = mock() - sys.modules[\"lib2\"] = mock() - sys.modules[\"lib2.module1\"] = mock() - sys.modules[\"lib2.module1.moduleB\"] = mock() # etc","title":"Mocking libraries"},{"location":"usage/#recommended-style-material","text":"Here are some CSS rules for the Material for MkDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : 4 px solid rgba ( 230 , 230 , 230 ); margin-bottom : 80 px ; }","title":"Recommended style (Material)"},{"location":"usage/#recommended-style-readthedocs","text":"Here are some CSS rules for the built-in ReadTheDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : 4 px solid rgba ( 230 , 230 , 230 ); margin-bottom : 60 px ; }","title":"Recommended style (ReadTheDocs)"},{"location":"reference/SUMMARY/","text":"mkdocstrings handlers python collector renderer","title":"SUMMARY"},{"location":"reference/mkdocstrings/handlers/python/","text":"This module implements a handler for the Python language. PythonHandler ( BaseHandler ) \u00a4 The Python handler class. Attributes: Name Type Description domain str The cross-documentation domain/language for this handler. enable_inventory bool Whether this handler is interested in enabling the creation of the objects.inv Sphinx inventory file. Source code in python/__init__.py class PythonHandler ( BaseHandler ): \"\"\"The Python handler class. Attributes: domain: The cross-documentation domain/language for this handler. enable_inventory: Whether this handler is interested in enabling the creation of the `objects.inv` Sphinx inventory file. \"\"\" domain : str = \"py\" # to match Sphinx's default domain enable_inventory : bool = True @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) load_inventory ( in_file , url , base_url = None , ** kwargs ) classmethod \u00a4 Yield items and their URLs from an inventory file streamed from in_file . This implements mkdocstrings' load_inventory \"protocol\" (see plugin.py). Parameters: Name Type Description Default in_file BinaryIO The binary file-like object to read the inventory from. required url str The URL that this file is being streamed from (used to guess base_url ). required base_url Optional[str] The URL that this inventory's sub-paths are relative to. None **kwargs Ignore additional arguments passed from the config. {} Yields: Type Description Iterator[Tuple[str, str]] Tuples of (item identifier, item URL). Source code in python/__init__.py @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) get_handler ( theme , custom_templates = None , setup_commands = None , ** config ) \u00a4 Simply return an instance of PythonHandler . Parameters: Name Type Description Default theme str The theme to use when rendering contents. required custom_templates Optional[str] Directory containing custom templates. None setup_commands Optional[List[str]] A list of commands as strings to be executed in the subprocess before pytkdocs . None config Any Configuration passed to the handler. {} Returns: Type Description PythonHandler An instance of PythonHandler . Source code in python/__init__.py def get_handler ( theme : str , # noqa: W0613 (unused argument config) custom_templates : Optional [ str ] = None , setup_commands : Optional [ List [ str ]] = None , ** config : Any , ) -> PythonHandler : \"\"\"Simply return an instance of `PythonHandler`. Arguments: theme: The theme to use when rendering contents. custom_templates: Directory containing custom templates. setup_commands: A list of commands as strings to be executed in the subprocess before `pytkdocs`. config: Configuration passed to the handler. Returns: An instance of `PythonHandler`. \"\"\" return PythonHandler ( collector = PythonCollector ( setup_commands = setup_commands ), renderer = PythonRenderer ( \"python\" , theme , custom_templates ), ) collector \u00a4 This module implements a collector for the Python language. It collects data with pytkdocs . PythonCollector ( BaseCollector ) \u00a4 The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Source code in python/collector.py class PythonCollector ( BaseCollector ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ]} \"\"\"The default selection options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`filters`** | `List[str]` | Filter members with regular expressions. | `[ \"!^_[^_]\" ]` **`members`** | `Union[bool, List[str]]` | Explicitly select the object members. | *`pytkdocs` default: `True`* If `members` is a list of names, filters are applied only on the members children (not the members themselves). If `members` is `False`, none are selected. If `members` is `True` or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: - `\"!^_\"`: exclude all objects starting with an underscore - `\"^__\"`: but select all objects starting with **two** underscores Obviously one could use a single filter instead: `\"!^_[^_]\"`, which is the default. \"\"\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate () default_config : dict \u00a4 The default selection options. Option Type Description Default filters List[str] Filter members with regular expressions. [ \"!^_[^_]\" ] members Union[bool, List[str]] Explicitly select the object members. pytkdocs default: True If members is a list of names, filters are applied only on the members children (not the members themselves). If members is False , none are selected. If members is True or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: \"!^_\" : exclude all objects starting with an underscore \"^__\" : but select all objects starting with two underscores Obviously one could use a single filter instead: \"!^_[^_]\" , which is the default. fallback_config \u00a4 The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. __init__ ( self , setup_commands = None ) special \u00a4 Initialize the object. When instantiating a Python collector, we open a subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None Source code in python/collector.py def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) collect ( self , identifier , config ) \u00a4 Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description Any The collected object-tree. Source code in python/collector.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result teardown ( self ) \u00a4 Terminate the opened subprocess, set it to None . Source code in python/collector.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate () rebuild_category_lists ( obj ) \u00a4 Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/collector.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child ) renderer \u00a4 This module implements a renderer for the Python language. PythonRenderer ( BaseRenderer ) \u00a4 The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Attributes: Name Type Description fallback_theme str The theme to fallback to. default_config dict The default rendering options, see default_config . Source code in python/renderer.py class PythonRenderer ( BaseRenderer ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. Attributes: fallback_theme: The theme to fallback to. default_config: The default rendering options, see [`default_config`][mkdocstrings.handlers.python.PythonRenderer.default_config]. \"\"\" fallback_theme = \"material\" default_config : dict = { \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\"The default rendering options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`show_root_heading`** | `bool` | Show the heading of the object at the root of the documentation tree. | `False` **`show_root_toc_entry`** | `bool` | If the root heading is not shown, at least add a ToC entry for it. | `True` **`show_root_full_path`** | `bool` | Show the full Python path for the root object heading. | `True` **`show_object_full_path`** | `bool` | Show the full Python path of every object. | `False` **`show_root_members_full_path`** | `bool` | Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, `show_object_full_path` overrides. | `False` **`show_category_heading`** | `bool` | When grouped by categories, show a heading for each category. | `False` **`show_if_no_docstring`** | `bool` | Show the object heading even if it has no docstring or children with docstrings. | `False` **`show_signature`** | `bool` | Show method and function signatures. | `True` **`show_signature_annotations`** | `bool` | Show the type annotations in method and function signatures. | `False` **`show_source`** | `bool` | Show the source code of this object. | `True` **`show_bases`** | `bool` | Show the base classes of a class. | `True` **`group_by_category`** | `bool` | Group the object's children by categories: attributes, classes, functions, methods, and modules. | `True` **`heading_level`** | `int` | The initial heading level to use. | `2` **`members_order`** | `str` | The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. | `alphabetical` \"\"\" # noqa: E501 def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief ) default_config : dict \u00a4 The default rendering options. Option Type Description Default show_root_heading bool Show the heading of the object at the root of the documentation tree. False show_root_toc_entry bool If the root heading is not shown, at least add a ToC entry for it. True show_root_full_path bool Show the full Python path for the root object heading. True show_object_full_path bool Show the full Python path of every object. False show_root_members_full_path bool Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, show_object_full_path overrides. False show_category_heading bool When grouped by categories, show a heading for each category. False show_if_no_docstring bool Show the object heading even if it has no docstring or children with docstrings. False show_signature bool Show method and function signatures. True show_signature_annotations bool Show the type annotations in method and function signatures. False show_source bool Show the source code of this object. True show_bases bool Show the base classes of a class. True group_by_category bool Group the object's children by categories: attributes, classes, functions, methods, and modules. True heading_level int The initial heading level to use. 2 members_order str The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. alphabetical do_brief_xref ( self , path ) \u00a4 Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/renderer.py def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief ) get_anchors ( self , data ) \u00a4 Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data Any The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/renderer.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () render ( self , data , config ) \u00a4 Render a template using provided data and configuration options. Parameters: Name Type Description Default data Any The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/renderer.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) update_env ( self , md , config ) \u00a4 Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/renderer.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref sort_object ( obj , sort_function ) \u00a4 Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj Any The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[Any], Any] The sort key function used to determine the order of elements. required Source code in python/renderer.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"python"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.PythonHandler","text":"The Python handler class. Attributes: Name Type Description domain str The cross-documentation domain/language for this handler. enable_inventory bool Whether this handler is interested in enabling the creation of the objects.inv Sphinx inventory file. Source code in python/__init__.py class PythonHandler ( BaseHandler ): \"\"\"The Python handler class. Attributes: domain: The cross-documentation domain/language for this handler. enable_inventory: Whether this handler is interested in enabling the creation of the `objects.inv` Sphinx inventory file. \"\"\" domain : str = \"py\" # to match Sphinx's default domain enable_inventory : bool = True @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri )","title":"PythonHandler"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.PythonHandler.load_inventory","text":"Yield items and their URLs from an inventory file streamed from in_file . This implements mkdocstrings' load_inventory \"protocol\" (see plugin.py). Parameters: Name Type Description Default in_file BinaryIO The binary file-like object to read the inventory from. required url str The URL that this file is being streamed from (used to guess base_url ). required base_url Optional[str] The URL that this inventory's sub-paths are relative to. None **kwargs Ignore additional arguments passed from the config. {} Yields: Type Description Iterator[Tuple[str, str]] Tuples of (item identifier, item URL). Source code in python/__init__.py @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri )","title":"load_inventory()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.get_handler","text":"Simply return an instance of PythonHandler . Parameters: Name Type Description Default theme str The theme to use when rendering contents. required custom_templates Optional[str] Directory containing custom templates. None setup_commands Optional[List[str]] A list of commands as strings to be executed in the subprocess before pytkdocs . None config Any Configuration passed to the handler. {} Returns: Type Description PythonHandler An instance of PythonHandler . Source code in python/__init__.py def get_handler ( theme : str , # noqa: W0613 (unused argument config) custom_templates : Optional [ str ] = None , setup_commands : Optional [ List [ str ]] = None , ** config : Any , ) -> PythonHandler : \"\"\"Simply return an instance of `PythonHandler`. Arguments: theme: The theme to use when rendering contents. custom_templates: Directory containing custom templates. setup_commands: A list of commands as strings to be executed in the subprocess before `pytkdocs`. config: Configuration passed to the handler. Returns: An instance of `PythonHandler`. \"\"\" return PythonHandler ( collector = PythonCollector ( setup_commands = setup_commands ), renderer = PythonRenderer ( \"python\" , theme , custom_templates ), )","title":"get_handler()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector","text":"This module implements a collector for the Python language. It collects data with pytkdocs .","title":"collector"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.PythonCollector","text":"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Source code in python/collector.py class PythonCollector ( BaseCollector ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ]} \"\"\"The default selection options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`filters`** | `List[str]` | Filter members with regular expressions. | `[ \"!^_[^_]\" ]` **`members`** | `Union[bool, List[str]]` | Explicitly select the object members. | *`pytkdocs` default: `True`* If `members` is a list of names, filters are applied only on the members children (not the members themselves). If `members` is `False`, none are selected. If `members` is `True` or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: - `\"!^_\"`: exclude all objects starting with an underscore - `\"^__\"`: but select all objects starting with **two** underscores Obviously one could use a single filter instead: `\"!^_[^_]\"`, which is the default. \"\"\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate ()","title":"PythonCollector"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.PythonCollector.default_config","text":"The default selection options. Option Type Description Default filters List[str] Filter members with regular expressions. [ \"!^_[^_]\" ] members Union[bool, List[str]] Explicitly select the object members. pytkdocs default: True If members is a list of names, filters are applied only on the members children (not the members themselves). If members is False , none are selected. If members is True or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: \"!^_\" : exclude all objects starting with an underscore \"^__\" : but select all objects starting with two underscores Obviously one could use a single filter instead: \"!^_[^_]\" , which is the default.","title":"default_config"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.PythonCollector.fallback_config","text":"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings.","title":"fallback_config"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.PythonCollector.__init__","text":"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None Source code in python/collector.py def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , )","title":"__init__()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.PythonCollector.collect","text":"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description Any The collected object-tree. Source code in python/collector.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result","title":"collect()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.PythonCollector.teardown","text":"Terminate the opened subprocess, set it to None . Source code in python/collector.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate ()","title":"teardown()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.collector.rebuild_category_lists","text":"Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/collector.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child )","title":"rebuild_category_lists()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer","text":"This module implements a renderer for the Python language.","title":"renderer"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.PythonRenderer","text":"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Attributes: Name Type Description fallback_theme str The theme to fallback to. default_config dict The default rendering options, see default_config . Source code in python/renderer.py class PythonRenderer ( BaseRenderer ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. Attributes: fallback_theme: The theme to fallback to. default_config: The default rendering options, see [`default_config`][mkdocstrings.handlers.python.PythonRenderer.default_config]. \"\"\" fallback_theme = \"material\" default_config : dict = { \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\"The default rendering options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`show_root_heading`** | `bool` | Show the heading of the object at the root of the documentation tree. | `False` **`show_root_toc_entry`** | `bool` | If the root heading is not shown, at least add a ToC entry for it. | `True` **`show_root_full_path`** | `bool` | Show the full Python path for the root object heading. | `True` **`show_object_full_path`** | `bool` | Show the full Python path of every object. | `False` **`show_root_members_full_path`** | `bool` | Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, `show_object_full_path` overrides. | `False` **`show_category_heading`** | `bool` | When grouped by categories, show a heading for each category. | `False` **`show_if_no_docstring`** | `bool` | Show the object heading even if it has no docstring or children with docstrings. | `False` **`show_signature`** | `bool` | Show method and function signatures. | `True` **`show_signature_annotations`** | `bool` | Show the type annotations in method and function signatures. | `False` **`show_source`** | `bool` | Show the source code of this object. | `True` **`show_bases`** | `bool` | Show the base classes of a class. | `True` **`group_by_category`** | `bool` | Group the object's children by categories: attributes, classes, functions, methods, and modules. | `True` **`heading_level`** | `int` | The initial heading level to use. | `2` **`members_order`** | `str` | The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. | `alphabetical` \"\"\" # noqa: E501 def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief )","title":"PythonRenderer"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.PythonRenderer.default_config","text":"The default rendering options. Option Type Description Default show_root_heading bool Show the heading of the object at the root of the documentation tree. False show_root_toc_entry bool If the root heading is not shown, at least add a ToC entry for it. True show_root_full_path bool Show the full Python path for the root object heading. True show_object_full_path bool Show the full Python path of every object. False show_root_members_full_path bool Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, show_object_full_path overrides. False show_category_heading bool When grouped by categories, show a heading for each category. False show_if_no_docstring bool Show the object heading even if it has no docstring or children with docstrings. False show_signature bool Show method and function signatures. True show_signature_annotations bool Show the type annotations in method and function signatures. False show_source bool Show the source code of this object. True show_bases bool Show the base classes of a class. True group_by_category bool Group the object's children by categories: attributes, classes, functions, methods, and modules. True heading_level int The initial heading level to use. 2 members_order str The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. alphabetical","title":"default_config"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.PythonRenderer.do_brief_xref","text":"Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/renderer.py def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief )","title":"do_brief_xref()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.PythonRenderer.get_anchors","text":"Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data Any The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/renderer.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return ()","title":"get_anchors()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.PythonRenderer.render","text":"Render a template using provided data and configuration options. Parameters: Name Type Description Default data Any The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/renderer.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, )","title":"render()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.PythonRenderer.update_env","text":"Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/renderer.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref","title":"update_env()"},{"location":"reference/mkdocstrings/handlers/python/#mkdocstrings.handlers.python.renderer.sort_object","text":"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj Any The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[Any], Any] The sort key function used to determine the order of elements. required Source code in python/renderer.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"sort_object()"},{"location":"reference/mkdocstrings/handlers/python/collector/","text":"This module implements a collector for the Python language. It collects data with pytkdocs . PythonCollector ( BaseCollector ) \u00a4 The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Source code in python/collector.py class PythonCollector ( BaseCollector ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ]} \"\"\"The default selection options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`filters`** | `List[str]` | Filter members with regular expressions. | `[ \"!^_[^_]\" ]` **`members`** | `Union[bool, List[str]]` | Explicitly select the object members. | *`pytkdocs` default: `True`* If `members` is a list of names, filters are applied only on the members children (not the members themselves). If `members` is `False`, none are selected. If `members` is `True` or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: - `\"!^_\"`: exclude all objects starting with an underscore - `\"^__\"`: but select all objects starting with **two** underscores Obviously one could use a single filter instead: `\"!^_[^_]\"`, which is the default. \"\"\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate () default_config : dict \u00a4 The default selection options. Option Type Description Default filters List[str] Filter members with regular expressions. [ \"!^_[^_]\" ] members Union[bool, List[str]] Explicitly select the object members. pytkdocs default: True If members is a list of names, filters are applied only on the members children (not the members themselves). If members is False , none are selected. If members is True or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: \"!^_\" : exclude all objects starting with an underscore \"^__\" : but select all objects starting with two underscores Obviously one could use a single filter instead: \"!^_[^_]\" , which is the default. fallback_config \u00a4 The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. __init__ ( self , setup_commands = None ) special \u00a4 Initialize the object. When instantiating a Python collector, we open a subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None Source code in python/collector.py def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) collect ( self , identifier , config ) \u00a4 Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description Any The collected object-tree. Source code in python/collector.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result teardown ( self ) \u00a4 Terminate the opened subprocess, set it to None . Source code in python/collector.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate () rebuild_category_lists ( obj ) \u00a4 Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/collector.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child )","title":"collector"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.PythonCollector","text":"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Source code in python/collector.py class PythonCollector ( BaseCollector ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ]} \"\"\"The default selection options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`filters`** | `List[str]` | Filter members with regular expressions. | `[ \"!^_[^_]\" ]` **`members`** | `Union[bool, List[str]]` | Explicitly select the object members. | *`pytkdocs` default: `True`* If `members` is a list of names, filters are applied only on the members children (not the members themselves). If `members` is `False`, none are selected. If `members` is `True` or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: - `\"!^_\"`: exclude all objects starting with an underscore - `\"^__\"`: but select all objects starting with **two** underscores Obviously one could use a single filter instead: `\"!^_[^_]\"`, which is the default. \"\"\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate ()","title":"PythonCollector"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.PythonCollector.default_config","text":"The default selection options. Option Type Description Default filters List[str] Filter members with regular expressions. [ \"!^_[^_]\" ] members Union[bool, List[str]] Explicitly select the object members. pytkdocs default: True If members is a list of names, filters are applied only on the members children (not the members themselves). If members is False , none are selected. If members is True or an empty list, filters are applied on all members and their children. Members affect only the first layer of objects, while filters affect the whole object-tree recursively. Every filters is run against every object name. An object can be un-selected by a filter and re-selected by the next one: \"!^_\" : exclude all objects starting with an underscore \"^__\" : but select all objects starting with two underscores Obviously one could use a single filter instead: \"!^_[^_]\" , which is the default.","title":"default_config"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.PythonCollector.fallback_config","text":"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings.","title":"fallback_config"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.PythonCollector.__init__","text":"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None Source code in python/collector.py def __init__ ( self , setup_commands : Optional [ List [ str ]] = None ) -> None : \"\"\"Initialize the object. When instantiating a Python collector, we open a subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Arguments: setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. \"\"\" log . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands = [ \"import sys\" , \"from io import StringIO\" , \"from pytkdocs.cli import main as pytkdocs\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , )","title":"__init__()"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.PythonCollector.collect","text":"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description Any The collected object-tree. Source code in python/collector.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings.handlers.python.collector.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = ChainMap ( config , self . default_config ) log . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) log . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore log . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore log . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: log . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : log . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] log . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result","title":"collect()"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.PythonCollector.teardown","text":"Terminate the opened subprocess, set it to None . Source code in python/collector.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" log . debug ( \"Tearing process down\" ) self . process . terminate ()","title":"teardown()"},{"location":"reference/mkdocstrings/handlers/python/collector/#mkdocstrings.handlers.python.collector.rebuild_category_lists","text":"Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/collector.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child )","title":"rebuild_category_lists()"},{"location":"reference/mkdocstrings/handlers/python/renderer/","text":"This module implements a renderer for the Python language. PythonRenderer ( BaseRenderer ) \u00a4 The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Attributes: Name Type Description fallback_theme str The theme to fallback to. default_config dict The default rendering options, see default_config . Source code in python/renderer.py class PythonRenderer ( BaseRenderer ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. Attributes: fallback_theme: The theme to fallback to. default_config: The default rendering options, see [`default_config`][mkdocstrings.handlers.python.PythonRenderer.default_config]. \"\"\" fallback_theme = \"material\" default_config : dict = { \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\"The default rendering options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`show_root_heading`** | `bool` | Show the heading of the object at the root of the documentation tree. | `False` **`show_root_toc_entry`** | `bool` | If the root heading is not shown, at least add a ToC entry for it. | `True` **`show_root_full_path`** | `bool` | Show the full Python path for the root object heading. | `True` **`show_object_full_path`** | `bool` | Show the full Python path of every object. | `False` **`show_root_members_full_path`** | `bool` | Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, `show_object_full_path` overrides. | `False` **`show_category_heading`** | `bool` | When grouped by categories, show a heading for each category. | `False` **`show_if_no_docstring`** | `bool` | Show the object heading even if it has no docstring or children with docstrings. | `False` **`show_signature`** | `bool` | Show method and function signatures. | `True` **`show_signature_annotations`** | `bool` | Show the type annotations in method and function signatures. | `False` **`show_source`** | `bool` | Show the source code of this object. | `True` **`show_bases`** | `bool` | Show the base classes of a class. | `True` **`group_by_category`** | `bool` | Group the object's children by categories: attributes, classes, functions, methods, and modules. | `True` **`heading_level`** | `int` | The initial heading level to use. | `2` **`members_order`** | `str` | The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. | `alphabetical` \"\"\" # noqa: E501 def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief ) default_config : dict \u00a4 The default rendering options. Option Type Description Default show_root_heading bool Show the heading of the object at the root of the documentation tree. False show_root_toc_entry bool If the root heading is not shown, at least add a ToC entry for it. True show_root_full_path bool Show the full Python path for the root object heading. True show_object_full_path bool Show the full Python path of every object. False show_root_members_full_path bool Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, show_object_full_path overrides. False show_category_heading bool When grouped by categories, show a heading for each category. False show_if_no_docstring bool Show the object heading even if it has no docstring or children with docstrings. False show_signature bool Show method and function signatures. True show_signature_annotations bool Show the type annotations in method and function signatures. False show_source bool Show the source code of this object. True show_bases bool Show the base classes of a class. True group_by_category bool Group the object's children by categories: attributes, classes, functions, methods, and modules. True heading_level int The initial heading level to use. 2 members_order str The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. alphabetical do_brief_xref ( self , path ) \u00a4 Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/renderer.py def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief ) get_anchors ( self , data ) \u00a4 Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data Any The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/renderer.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () render ( self , data , config ) \u00a4 Render a template using provided data and configuration options. Parameters: Name Type Description Default data Any The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/renderer.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) update_env ( self , md , config ) \u00a4 Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/renderer.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref sort_object ( obj , sort_function ) \u00a4 Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj Any The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[Any], Any] The sort key function used to determine the order of elements. required Source code in python/renderer.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"renderer"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.PythonRenderer","text":"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the render method, and overrides the update_env method of the BaseRenderer class . Attributes: Name Type Description fallback_theme str The theme to fallback to. default_config dict The default rendering options, see default_config . Source code in python/renderer.py class PythonRenderer ( BaseRenderer ): \"\"\"The class responsible for loading Jinja templates and rendering them. It defines some configuration options, implements the `render` method, and overrides the `update_env` method of the [`BaseRenderer` class][mkdocstrings.handlers.base.BaseRenderer]. Attributes: fallback_theme: The theme to fallback to. default_config: The default rendering options, see [`default_config`][mkdocstrings.handlers.python.PythonRenderer.default_config]. \"\"\" fallback_theme = \"material\" default_config : dict = { \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\"The default rendering options. Option | Type | Description | Default ------ | ---- | ----------- | ------- **`show_root_heading`** | `bool` | Show the heading of the object at the root of the documentation tree. | `False` **`show_root_toc_entry`** | `bool` | If the root heading is not shown, at least add a ToC entry for it. | `True` **`show_root_full_path`** | `bool` | Show the full Python path for the root object heading. | `True` **`show_object_full_path`** | `bool` | Show the full Python path of every object. | `False` **`show_root_members_full_path`** | `bool` | Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, `show_object_full_path` overrides. | `False` **`show_category_heading`** | `bool` | When grouped by categories, show a heading for each category. | `False` **`show_if_no_docstring`** | `bool` | Show the object heading even if it has no docstring or children with docstrings. | `False` **`show_signature`** | `bool` | Show method and function signatures. | `True` **`show_signature_annotations`** | `bool` | Show the type annotations in method and function signatures. | `False` **`show_source`** | `bool` | Show the source code of this object. | `True` **`show_bases`** | `bool` | Show the base classes of a class. | `True` **`group_by_category`** | `bool` | Group the object's children by categories: attributes, classes, functions, methods, and modules. | `True` **`heading_level`** | `int` | The initial heading level to use. | `2` **`members_order`** | `str` | The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. | `alphabetical` \"\"\" # noqa: E501 def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief )","title":"PythonRenderer"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.PythonRenderer.default_config","text":"The default rendering options. Option Type Description Default show_root_heading bool Show the heading of the object at the root of the documentation tree. False show_root_toc_entry bool If the root heading is not shown, at least add a ToC entry for it. True show_root_full_path bool Show the full Python path for the root object heading. True show_object_full_path bool Show the full Python path of every object. False show_root_members_full_path bool Show the full Python path of objects that are children of the root object (for example, classes in a module). When False, show_object_full_path overrides. False show_category_heading bool When grouped by categories, show a heading for each category. False show_if_no_docstring bool Show the object heading even if it has no docstring or children with docstrings. False show_signature bool Show method and function signatures. True show_signature_annotations bool Show the type annotations in method and function signatures. False show_source bool Show the source code of this object. True show_bases bool Show the base classes of a class. True group_by_category bool Group the object's children by categories: attributes, classes, functions, methods, and modules. True heading_level int The initial heading level to use. 2 members_order str The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. alphabetical","title":"default_config"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.PythonRenderer.do_brief_xref","text":"Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/renderer.py def do_brief_xref ( self , path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief )","title":"do_brief_xref()"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.PythonRenderer.get_anchors","text":"Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data Any The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/renderer.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return ()","title":"get_anchors()"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.PythonRenderer.render","text":"Render a template using provided data and configuration options. Parameters: Name Type Description Default data Any The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/renderer.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = _sort_key_alphabetical elif members_order == \"source\" : sort_function = _sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, )","title":"render()"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.PythonRenderer.update_env","text":"Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/renderer.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = self . do_brief_xref","title":"update_env()"},{"location":"reference/mkdocstrings/handlers/python/renderer/#mkdocstrings.handlers.python.renderer.sort_object","text":"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj Any The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[Any], Any] The sort key function used to determine the order of elements. required Source code in python/renderer.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"sort_object()"},{"location":"coverage/","text":".md-content { max-width: none !important; } article h1, article > a { display: none; } var coviframe = document.getElementById(\"coviframe\"); function resizeIframe() { coviframe.style.height = coviframe.contentWindow.document.documentElement.offsetHeight + 'px'; } coviframe.contentWindow.document.body.onclick = function() { coviframe.contentWindow.location.reload(); }","title":"Coverage report"}]}