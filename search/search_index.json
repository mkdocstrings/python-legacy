{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"mkdocstrings-python-legacy The legacy Python handler for mkdocstrings . Warning We suggest using the new handler instead: mkdocstrings-python . Installation \u00a4 You can install this handler as a mkdocstrings extra: pyproject.toml # PEP 621 dependencies declaration # adapt to your dependencies manager [project] dependencies = [ \"mkdocstrings[python-legacy]>=0.18\" , ] You can also explicitely depend on the handler: pyproject.toml # PEP 621 dependencies declaration # adapt to your dependencies manager [project] dependencies = [ \"mkdocstrings-python-legacy\" , ] Preview \u00a4 Features \u00a4 Data collection from source code : collection of the object-tree and the docstrings is done thanks to pytkdocs . Support for type annotations: pytkdocs collects your type annotations and mkdocstrings uses them to display parameters types or return types. Recursive documentation of Python objects: just use the module dotted-path as identifier, and you get the full module docs. You don't need to inject documentation for each class, function, etc. Support for documented attributes: attributes (variables) followed by a docstring (triple-quoted string) will be recognized by Griffe in modules, classes and even in __init__ methods. Multiple docstring-styles support: common support for Google-style, Numpydoc-style, and Sphinx-style docstrings. Admonition support in Google docstrings: blocks like Note: or Warning: will be transformed to their admonition equivalent. We do not support nested admonitions in docstrings! Every object has a TOC entry: we render a heading for each object, meaning MkDocs picks them into the Table of Contents, which is nicely display by the Material theme. Thanks to mkdocstrings cross-reference ability, you can reference other objects within your docstrings, with the classic Markdown syntax: [this object][package.module.object] or directly with [package.module.object][] Source code display: mkdocstrings can add a collapsible div containing the highlighted source code of the Python object.","title":"Overview"},{"location":"#installation","text":"You can install this handler as a mkdocstrings extra: pyproject.toml # PEP 621 dependencies declaration # adapt to your dependencies manager [project] dependencies = [ \"mkdocstrings[python-legacy]>=0.18\" , ] You can also explicitely depend on the handler: pyproject.toml # PEP 621 dependencies declaration # adapt to your dependencies manager [project] dependencies = [ \"mkdocstrings-python-legacy\" , ]","title":"Installation"},{"location":"#preview","text":"","title":"Preview"},{"location":"#features","text":"Data collection from source code : collection of the object-tree and the docstrings is done thanks to pytkdocs . Support for type annotations: pytkdocs collects your type annotations and mkdocstrings uses them to display parameters types or return types. Recursive documentation of Python objects: just use the module dotted-path as identifier, and you get the full module docs. You don't need to inject documentation for each class, function, etc. Support for documented attributes: attributes (variables) followed by a docstring (triple-quoted string) will be recognized by Griffe in modules, classes and even in __init__ methods. Multiple docstring-styles support: common support for Google-style, Numpydoc-style, and Sphinx-style docstrings. Admonition support in Google docstrings: blocks like Note: or Warning: will be transformed to their admonition equivalent. We do not support nested admonitions in docstrings! Every object has a TOC entry: we render a heading for each object, meaning MkDocs picks them into the Table of Contents, which is nicely display by the Material theme. Thanks to mkdocstrings cross-reference ability, you can reference other objects within your docstrings, with the classic Markdown syntax: [this object][package.module.object] or directly with [package.module.object][] Source code display: mkdocstrings can add a collapsible div containing the highlighted source code of the Python object.","title":"Features"},{"location":"changelog/","text":"Changelog \u00a4 All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning . 0.2.3 - 2022-05-28 \u00a4 Compare with 0.2.2 Packaging / Dependencies \u00a4 Depend on mkdocstrings 0.19 ( 71123dc by Timoth\u00e9e Mazzucotelli). Code Refactoring \u00a4 Unify default configurations ( 47c53fc by Timoth\u00e9e Mazzucotelli). Stop using deprecated base classes ( 5a28b12 by Timoth\u00e9e Mazzucotelli). Use new mkdocstrings_handlers namespace ( d688c87 by Timoth\u00e9e Mazzucotelli). 0.2.2 - 2022-02-19 \u00a4 Compare with 0.2.1 Bug Fixes \u00a4 Handle empty error in JSON output ( 0e7ab59 by rachmadani haryono). PR #1 0.2.1 - 2022-02-05 \u00a4 Compare with 0.2.0 Dependencies \u00a4 Require at least mkdocstrings 0.18 ( 09d8e9c by Timoth\u00e9e Mazzucotelli). 0.2.0 - 2022-02-03 \u00a4 Compare with 0.1.0 Features \u00a4 Add show_signature rendering option ( e741b37 by Will Da Silva). Dependencies \u00a4 Depend on mkdocstrings ( a154c05 by Timoth\u00e9e Mazzucotelli). Code Refactoring \u00a4 Add user warning about mkdocstrings extra ( 71ea2d8 by Timoth\u00e9e Mazzucotelli). 0.1.0 - 2021-12-18 \u00a4 Compare with first commit Features \u00a4 Copy code from mkdocstrings ( 720f91e by Timoth\u00e9e Mazzucotelli).","title":"Changelog"},{"location":"changelog/#changelog","text":"All notable changes to this project will be documented in this file. The format is based on Keep a Changelog and this project adheres to Semantic Versioning .","title":"Changelog"},{"location":"changelog/#023-2022-05-28","text":"Compare with 0.2.2","title":"0.2.3 - 2022-05-28"},{"location":"changelog/#packaging-dependencies","text":"Depend on mkdocstrings 0.19 ( 71123dc by Timoth\u00e9e Mazzucotelli).","title":"Packaging / Dependencies"},{"location":"changelog/#code-refactoring","text":"Unify default configurations ( 47c53fc by Timoth\u00e9e Mazzucotelli). Stop using deprecated base classes ( 5a28b12 by Timoth\u00e9e Mazzucotelli). Use new mkdocstrings_handlers namespace ( d688c87 by Timoth\u00e9e Mazzucotelli).","title":"Code Refactoring"},{"location":"changelog/#022-2022-02-19","text":"Compare with 0.2.1","title":"0.2.2 - 2022-02-19"},{"location":"changelog/#bug-fixes","text":"Handle empty error in JSON output ( 0e7ab59 by rachmadani haryono). PR #1","title":"Bug Fixes"},{"location":"changelog/#021-2022-02-05","text":"Compare with 0.2.0","title":"0.2.1 - 2022-02-05"},{"location":"changelog/#dependencies","text":"Require at least mkdocstrings 0.18 ( 09d8e9c by Timoth\u00e9e Mazzucotelli).","title":"Dependencies"},{"location":"changelog/#020-2022-02-03","text":"Compare with 0.1.0","title":"0.2.0 - 2022-02-03"},{"location":"changelog/#features","text":"Add show_signature rendering option ( e741b37 by Will Da Silva).","title":"Features"},{"location":"changelog/#dependencies_1","text":"Depend on mkdocstrings ( a154c05 by Timoth\u00e9e Mazzucotelli).","title":"Dependencies"},{"location":"changelog/#code-refactoring_1","text":"Add user warning about mkdocstrings extra ( 71ea2d8 by Timoth\u00e9e Mazzucotelli).","title":"Code Refactoring"},{"location":"changelog/#010-2021-12-18","text":"Compare with first commit","title":"0.1.0 - 2021-12-18"},{"location":"changelog/#features_1","text":"Copy code from mkdocstrings ( 720f91e by Timoth\u00e9e Mazzucotelli).","title":"Features"},{"location":"code_of_conduct/","text":"Contributor Covenant Code of Conduct \u00a4 Our Pledge \u00a4 In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation. Our Standards \u00a4 Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting Our Responsibilities \u00a4 Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful. Scope \u00a4 This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers. Enforcement \u00a4 Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at pawamoy@pm.me . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership. Attribution \u00a4 This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4","title":"Code of Conduct"},{"location":"code_of_conduct/#contributor-covenant-code-of-conduct","text":"","title":"Contributor Covenant Code of Conduct"},{"location":"code_of_conduct/#our-pledge","text":"In the interest of fostering an open and welcoming environment, we as contributors and maintainers pledge to making participation in our project and our community a harassment-free experience for everyone, regardless of age, body size, disability, ethnicity, gender identity and expression, level of experience, nationality, personal appearance, race, religion, or sexual identity and orientation.","title":"Our Pledge"},{"location":"code_of_conduct/#our-standards","text":"Examples of behavior that contributes to creating a positive environment include: Using welcoming and inclusive language Being respectful of differing viewpoints and experiences Gracefully accepting constructive criticism Focusing on what is best for the community Showing empathy towards other community members Examples of unacceptable behavior by participants include: The use of sexualized language or imagery and unwelcome sexual attention or advances Trolling, insulting/derogatory comments, and personal or political attacks Public or private harassment Publishing others' private information, such as a physical or electronic address, without explicit permission Other conduct which could reasonably be considered inappropriate in a professional setting","title":"Our Standards"},{"location":"code_of_conduct/#our-responsibilities","text":"Project maintainers are responsible for clarifying the standards of acceptable behavior and are expected to take appropriate and fair corrective action in response to any instances of unacceptable behavior. Project maintainers have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, or to ban temporarily or permanently any contributor for other behaviors that they deem inappropriate, threatening, offensive, or harmful.","title":"Our Responsibilities"},{"location":"code_of_conduct/#scope","text":"This Code of Conduct applies both within project spaces and in public spaces when an individual is representing the project or its community. Examples of representing a project or community include using an official project e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event. Representation of a project may be further defined and clarified by project maintainers.","title":"Scope"},{"location":"code_of_conduct/#enforcement","text":"Instances of abusive, harassing, or otherwise unacceptable behavior may be reported by contacting the project team at pawamoy@pm.me . All complaints will be reviewed and investigated and will result in a response that is deemed necessary and appropriate to the circumstances. The project team is obligated to maintain confidentiality with regard to the reporter of an incident. Further details of specific enforcement policies may be posted separately. Project maintainers who do not follow or enforce the Code of Conduct in good faith may face temporary or permanent repercussions as determined by other members of the project's leadership.","title":"Enforcement"},{"location":"code_of_conduct/#attribution","text":"This Code of Conduct is adapted from the Contributor Covenant , version 1.4, available at http://contributor-covenant.org/version/1/4","title":"Attribution"},{"location":"contributing/","text":"Contributing \u00a4 Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given. Environment setup \u00a4 Nothing easier! Fork and clone the repository, then: cd python-legacy make setup Note If it fails for some reason, you'll need to install PDM manually. You can install it with: python3 -m pip install --user pipx pipx install pdm Now you can try running make setup again, or simply pdm install . You now have the dependencies installed. Run make help to see all the available actions! Tasks \u00a4 This project uses duty to run tasks. A Makefile is also provided. The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you can do one of the following: export PYTHON_VERSIONS= : this will run the task with only the current Python version run the task directly with pdm run duty TASK The Makefile detects if a virtual environment is activated, so make will work the same with the virtualenv activated or not. Development \u00a4 As usual: create a new branch: git checkout -b feature-or-bugfix-name edit the code and/or the documentation Before committing: run make format to auto-format the code run make check to check everything (fix any warning) run make test to run the tests (fix any issue) if you updated the documentation or the project dependencies: run make docs-serve go to http://localhost:8000 and check that everything looks good follow our commit message convention If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review. Don't bother updating the changelog, we will take care of this. Commit message convention \u00a4 Commits messages must follow the Angular style : <type>[(scope)]: Subject [Body] Scope and body are optional. Type can be: build : About packaging, building wheels, etc. chore : About packaging or repo/files management. ci : About Continuous Integration. docs : About documentation. feat : New feature. fix : Bug fix. perf : About performance. refactor : Changes which are not features nor bug fixes. style : A change in code style/format. tests : About tests. Subject (and body) must be valid Markdown. If you write a body, please add issues references at the end: Body. References: #10, #11. Fixes #15. Pull requests guidelines \u00a4 Link to any related issue in the Pull Request message. During review, we recommend using fixups: # SHA is the SHA of the commit you want to fix git commit --fixup = SHA Once all the changes are approved, you can squash your commits: git rebase -i --autosquash master And force-push: git push -f If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.","title":"Contributing"},{"location":"contributing/#contributing","text":"Contributions are welcome, and they are greatly appreciated! Every little bit helps, and credit will always be given.","title":"Contributing"},{"location":"contributing/#environment-setup","text":"Nothing easier! Fork and clone the repository, then: cd python-legacy make setup Note If it fails for some reason, you'll need to install PDM manually. You can install it with: python3 -m pip install --user pipx pipx install pdm Now you can try running make setup again, or simply pdm install . You now have the dependencies installed. Run make help to see all the available actions!","title":"Environment setup"},{"location":"contributing/#tasks","text":"This project uses duty to run tasks. A Makefile is also provided. The Makefile will try to run certain tasks on multiple Python versions. If for some reason you don't want to run the task on multiple Python versions, you can do one of the following: export PYTHON_VERSIONS= : this will run the task with only the current Python version run the task directly with pdm run duty TASK The Makefile detects if a virtual environment is activated, so make will work the same with the virtualenv activated or not.","title":"Tasks"},{"location":"contributing/#development","text":"As usual: create a new branch: git checkout -b feature-or-bugfix-name edit the code and/or the documentation Before committing: run make format to auto-format the code run make check to check everything (fix any warning) run make test to run the tests (fix any issue) if you updated the documentation or the project dependencies: run make docs-serve go to http://localhost:8000 and check that everything looks good follow our commit message convention If you are unsure about how to fix or ignore a warning, just let the continuous integration fail, and we will help you during review. Don't bother updating the changelog, we will take care of this.","title":"Development"},{"location":"contributing/#commit-message-convention","text":"Commits messages must follow the Angular style : <type>[(scope)]: Subject [Body] Scope and body are optional. Type can be: build : About packaging, building wheels, etc. chore : About packaging or repo/files management. ci : About Continuous Integration. docs : About documentation. feat : New feature. fix : Bug fix. perf : About performance. refactor : Changes which are not features nor bug fixes. style : A change in code style/format. tests : About tests. Subject (and body) must be valid Markdown. If you write a body, please add issues references at the end: Body. References: #10, #11. Fixes #15.","title":"Commit message convention"},{"location":"contributing/#pull-requests-guidelines","text":"Link to any related issue in the Pull Request message. During review, we recommend using fixups: # SHA is the SHA of the commit you want to fix git commit --fixup = SHA Once all the changes are approved, you can squash your commits: git rebase -i --autosquash master And force-push: git push -f If this seems all too complicated, you can push or force-push each new commit, and we will squash them ourselves if needed, before merging.","title":"Pull requests guidelines"},{"location":"credits/","text":"These projects were used to build mkdocstrings-python-legacy . Thank you! python | pdm | copier-pdm Runtime dependencies \u00a4 Project Summary Version (accepted) Version (last resolved) License astunparse An AST unparser for Python >=1.6; python_version < \"3.9\" 1.6.3 BSD cached-property A decorator for caching properties in classes. >=1.5; python_version < \"3.8\" 1.5.2 ? click Composable command line interface toolkit >=3.3 8.1.2 BSD-3-Clause colorama Cross-platform colored terminal text. ; platform_system == \"Windows\" 0.4.4 BSD ghp-import Copy your docs directly to the gh-pages branch. >=1.0 2.0.2 Apache Software License importlib-metadata Read metadata from Python packages >=4.4; python_version < \"3.10\" 4.11.3 Apache Software License jinja2 A very fast and expressive template engine. >=2.11.1 3.1.1 BSD-3-Clause markdown Python implementation of Markdown. >=3.3 3.3.6 BSD License markupsafe Safely add untrusted strings to HTML/XML markup. >=1.1 2.1.1 BSD-3-Clause mergedeep A deep merge function for \ud83d\udc0d. >=1.3.4 1.3.4 MIT License mkdocs Project documentation with Markdown. >=1.2 1.3.0 BSD mkdocs-autorefs Automatically link across pages in MkDocs. >=0.3.1 0.4.1 ISC License (ISCL) mkdocstrings Automatic documentation from sources, for MkDocs. >=0.19 0.18.1 ISC License (ISCL) mkdocstrings-python-legacy A legacy Python handler for mkdocstrings. >=0.2 0.2.2 ISC packaging Core utilities for Python packages >=20.5 21.3 BSD-2-Clause or Apache-2.0 pymdown-extensions Extension pack for Python Markdown. >=6.3 9.3 MIT License pyparsing Python parsing module !=3.0.5,>=2.0.2 3.0.7 MIT License python-dateutil Extensions to the standard Python datetime module >=2.8.1 2.8.2 Dual License pytkdocs Load Python objects documentation. >=0.14 0.16.1 ISC License (ISCL) pyyaml YAML parser and emitter for Python >=3.10 6.0 MIT pyyaml-env-tag A custom YAML tag for referencing environment variables in YAML files. >=0.1 0.1 MIT License six Python 2 and 3 compatibility utilities <2.0,>=1.6.1 1.16.0 MIT typing-extensions Backported and Experimental Type Hints for Python 3.5+ >=3.7; python_version < \"3.8\" 3.10.0.2 PSF watchdog Filesystem events monitoring >=2.0 2.1.7 Apache License 2.0 wheel A built-package format for Python <1.0,>=0.23.0 0.37.1 MIT zipp Backport of pathlib-compatible object wrapper for zip files >=0.5 3.7.0 MIT License Development dependencies \u00a4 Project Summary Version (accepted) Version (last resolved) License ansimarkup Produce colored terminal text with an xml-like markup ~=1.4 1.5.0 Revised BSD License astor Read/rewrite/write Python ASTs <0.9,>=0.8 0.8.1 BSD-3-Clause atomicwrites Atomic file writes. >=1.0; sys_platform == \"win32\" 1.4.0 ? attrs Classes Without Boilerplate >=19.2.0 21.4.0 MIT autoflake Removes unused imports and unused variables >=1.4 1.4 Expat License bandit Security oriented static analyser for python code. >=1.7.3 1.7.4 Apache-2.0 license black The uncompromising code formatter. >=21.10b0 22.3.0 MIT cached-property A decorator for caching properties in classes. ~=1.5; python_version < \"3.8\" 1.5.2 ? certifi Python package for providing Mozilla's CA Bundle. >=2017.4.17 2021.10.8 MPL-2.0 charset-normalizer The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet. ~=2.0.0; python_version >= \"3\" 2.0.12 MIT click Composable command line interface toolkit >=8.0.0 8.1.2 BSD-3-Clause colorama Cross-platform colored terminal text. ; platform_system == \"Windows\" 0.4.4 BSD coverage Code coverage measurement for Python [toml]>=5.2.1 6.3.2 Apache 2.0 darglint A utility for ensuring Google-style docstrings stay up to date with the source code. >=1.8 1.8.1 MIT dparse A parser for Python dependency files >=0.5.1 0.5.1 MIT license duty A simple task runner. >=0.7 0.7.0 ISC execnet execnet: rapid multi-Python deployment >=1.1 1.9.0 MIT failprint Run a command, print its output only if it fails. ~=0.8 0.8.0 ISC flake8 the modular source code checker: pep8 pyflakes and co 3.9.2 MIT flake8-bandit Automated security testing with bandit and flake8. >=2.1 3.0.0 MIT flake8-black flake8 plugin to call black as a code style validator >=0.2 0.3.2 MIT flake8-bugbear A plugin for flake8 finding likely bugs and design problems in your program. Contains warnings that don't belong in pyflakes and pycodestyle. >=21.9 22.3.23 MIT flake8-builtins Check for python builtins being used as variables or parameters. >=1.5 1.5.3 GPL version 2 flake8-comprehensions A flake8 plugin to help you write better list/set/dict comprehensions. >=3.7 3.8.0 MIT flake8-docstrings Extension for flake8 which uses pydocstyle to check docstrings >=1.6 1.6.0 MIT License flake8-plugin-utils The package provides base classes and utils for flake8 plugin writing <2.0.0,>=1.3.2 1.3.2 MIT flake8-polyfill Polyfill package for Flake8 plugins 1.0.2 MIT flake8-pytest-style A flake8 plugin checking common style issues or inconsistencies with pytest-based tests. >=1.5 1.6.0 MIT flake8-string-format string format checker, plugin for flake8 >=0.3 0.3.0 MIT License flake8-tidy-imports A flake8 plugin that helps you write tidier imports. >=4.5 4.6.0 MIT flake8-variables-names A flake8 extension that helps to make more readable variables names >=0.0 0.0.5 MIT ghp-import Copy your docs directly to the gh-pages branch. >=1.0 2.0.2 Apache Software License git-changelog Automatic Changelog generator using Jinja2 templates. >=0.4 0.5.0 ISC gitdb Git Object Database <5,>=4.0.1 4.0.9 BSD License gitpython GitPython is a python library used to interact with Git repositories >=1.0.1 3.1.27 BSD idna Internationalized Domain Names in Applications (IDNA) <4,>=2.5; python_version >= \"3\" 3.3 BSD-3-Clause importlib-metadata Read metadata from Python packages ; python_version < \"3.8\" 4.11.3 Apache Software License iniconfig iniconfig: brain-dead simple config-ini parsing 1.1.1 MIT License isort A Python utility / library to sort Python imports. >=5.10 5.10.1 MIT jinja2 A very fast and expressive template engine. <4,>=2.11 3.1.1 BSD-3-Clause markdown Python implementation of Markdown. <4.0,>=3.3 3.3.6 BSD License markdown-callouts Markdown extension: a classier syntax for admonitions >=0.2 0.2.0 MIT markdown-exec Utilities to execute code blocks in Markdown files. >=0.5 0.6.0 ISC markupsafe Safely add untrusted strings to HTML/XML markup. >=2.0 2.1.1 BSD-3-Clause mccabe McCabe checker, plugin for flake8 <0.7.0,>=0.6.0 0.6.1 Expat license mergedeep A deep merge function for \ud83d\udc0d. >=1.3.4 1.3.4 MIT License mkdocs Project documentation with Markdown. >=1.3 1.3.0 BSD mkdocs-coverage MkDocs plugin to integrate your coverage HTML report into your site. >=0.2 0.2.5 ISC License (ISCL) mkdocs-gen-files MkDocs plugin to programmatically generate documentation pages during the build >=0.3 0.3.4 MIT mkdocs-literate-nav MkDocs plugin to specify the navigation in Markdown instead of YAML >=0.4 0.4.1 MIT mkdocs-material A Material Design theme for MkDocs >=7.3 8.2.8 MIT mkdocs-material-extensions Extension pack for Python Markdown. >=1.0.3 1.0.3 MIT License mkdocs-section-index MkDocs plugin to allow clickable sections that lead to an index page >=0.3 0.3.4 MIT mypy Optional static typing for Python >=0.910 0.942 MIT License mypy-extensions Experimental type system extensions for programs checked with the mypy typechecker. >=0.4.3 0.4.3 MIT License packaging Core utilities for Python packages >=20.5 21.3 BSD-2-Clause or Apache-2.0 pathspec Utility library for gitignore style pattern matching of file paths. >=0.9.0 0.9.0 MPL 2.0 pbr Python Build Reasonableness !=2.1.0,>=2.0.0 5.8.1 Apache Software License pep8-naming Check PEP-8 naming conventions, plugin for flake8 >=0.12 0.12.1 Expat license platformdirs A small Python module for determining appropriate platform-specific dirs, e.g. a \"user data dir\". >=2 2.5.1 MIT pluggy plugin and hook calling mechanisms for python <2.0,>=0.12 1.0.0 MIT ptyprocess Run a subprocess in a pseudo terminal ~=0.6; sys_platform != \"win32\" 0.7.0 ISC License (ISCL) py library with cross-python path, ini-parsing, io, code, log facilities >=1.8.2 1.11.0 MIT license pycodestyle Python style guide checker 2.7.0 Expat license pydocstyle Python docstring style checker >=2.1 6.1.1 MIT pyflakes passive checker of Python programs >=1.1.0 2.3.1 MIT pygments Pygments is a syntax highlighting package written in Python. >=2.10 2.11.2 BSD License pymdown-extensions Extension pack for Python Markdown. >=9 9.3 MIT License pyparsing Python parsing module !=3.0.5,>=2.0.2 3.0.7 MIT License pytest pytest: simple powerful testing with Python >=6.2 7.1.1 MIT pytest-cov Pytest plugin for measuring coverage. >=3.0 3.0.0 MIT pytest-forked run tests in isolated forked subprocesses 1.4.0 MIT pytest-randomly Pytest plugin to randomly order tests and control random.seed. >=3.10 3.11.0 MIT pytest-xdist pytest xdist plugin for distributed testing and loop-on-failing modes >=2.4 2.5.0 MIT python-dateutil Extensions to the standard Python datetime module >=2.8.1 2.8.2 Dual License pyyaml YAML parser and emitter for Python >=3.10 6.0 MIT pyyaml-env-tag A custom YAML tag for referencing environment variables in YAML files. >=0.1 0.1 MIT License requests Python HTTP for Humans. 2.27.1 Apache 2.0 safety Checks installed dependencies for known vulnerabilities. >=1.10 1.10.3 MIT license semver Python helper for Semantic Versioning (http://semver.org/) ~=2.13 2.13.0 BSD setuptools Easily download, build, install, upgrade, and uninstall Python packages 61.3.0 MIT License six Python 2 and 3 compatibility utilities >=1.5 1.16.0 MIT smmap A pure Python implementation of a sliding window memory map manager <6,>=3.0.1 5.0.0 BSD snowballstemmer This package provides 29 stemmers for 28 languages generated from Snowball algorithms. 2.2.0 BSD-3-Clause stevedore Manage dynamic plugins for Python applications >=1.20.0 3.5.0 Apache Software License toml Python Library for Tom's Obvious, Minimal Language >=0.10 0.10.2 MIT tomli A lil' TOML parser >=1.1.0; python_version < \"3.11\" 2.0.1 MIT License typed-ast a fork of Python 2 and 3 ast modules with type comment support >=1.4.2; python_version < \"3.8\" and implementation_name == \"cpython\" 1.5.2 ? types-markdown Typing stubs for Markdown >=3.3 3.3.12 Apache-2.0 license types-toml Typing stubs for toml >=0.10 0.10.4 Apache-2.0 license typing-extensions Backported and Experimental Type Hints for Python 3.5+ >=3.10.0.0; python_version < \"3.10\" 3.10.0.2 PSF urllib3 HTTP library with thread-safe connection pooling, file post, and more. <1.27,>=1.21.1 1.26.9 MIT watchdog Filesystem events monitoring >=2.0 2.1.7 Apache License 2.0 wps-light The strictest and most opinionated python linter ever (lighter fork). >=0.15 0.15.3 MIT zipp Backport of pathlib-compatible object wrapper for zip files >=0.5 3.7.0 MIT License More credits from the author","title":"Credits"},{"location":"license/","text":"ISC License Copyright (c) 2021, Timoth\u00e9e Mazzucotelli Permission to use, copy, modify, and/or distribute this software for any purpose with or without fee is hereby granted, provided that the above copyright notice and this permission notice appear in all copies. THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.","title":"License"},{"location":"usage/","text":"Usage \u00a4 This is the documentation for the LEGACY Python handler To read the documentation for the NEW handler, go to the new handler documentation . The tool used by the legacy Python handler to collect documentation from Python source code is pytkdocs . It stands for (Python) Take Docs , and is supposed to be a pun on MkDocs ( Make Docs ?). Like every handler, the legacy Python handler accepts both global and local options. Global-only options \u00a4 Some options are global only , and go directly under the handler's name. import : this option is used to import Sphinx-compatible objects inventories from other documentation sites. For example, you can import the standard library objects inventory like this: mkdocs.yml plugins : - mkdocstrings : handlers : python : import : - https://docs.python-requests.org/en/master/objects.inv When importing an inventory, you enable automatic cross-references to other documentation sites like the standard library docs or any third-party package docs. Typically, you want to import the inventories of your project's dependencies, at least those that are used in the public API. Note This global option is common to all handlers, however they might implement it differently (or not even implement it). paths : this option is used to provide filesystem paths in which to search for Python modules. Non-absolute paths are computed as relative to MkDocs configuration file. Example: mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ src ] # search packages in the src folder More details at Finding modules . setup_commands : this option is used to instruct pytkdocs , the tool responsible for collecting data from sources, to run Python statements before starting to collect data. It is declared as a list of strings: mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import os - import django - os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"my_django_app.settings\") - django.setup() The setup commands are executed only once, when the pytkdocs background process is started. Global/local options \u00a4 The other options can be used both globally and locally, under the options key. For example, globally: mkdocs.yml plugins : - mkdocstrings : handlers : python : options : do_something : true ...and locally, overriding the global configuration: docs/some_page.md ::: package.module.class options: do_something: false These options affect how the documentation is collected from sources and renderered: headings, members, docstrings, etc. Headings options: heading_level ( int ): The initial heading level to use. Default: 2 . show_root_heading ( bool ): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after ::: ). Default: False . show_root_toc_entry ( bool ): If the root heading is not shown, at least add a ToC entry for it. Default: True . show_root_full_path ( bool ): Show the full Python path for the root object heading. Default: True . show_root_members_full_path ( bool ): Show the full Python path of the root members. Default: False . show_object_full_path ( bool ): Show the full Python path of every object. Default: False . show_category_heading ( bool ): When grouped by categories, show a heading for each category. Default: False . Members options: members ( list[str] | False | None ): An explicit list of members to render. Default: None . members_order ( str ): The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. Default: \"alphabetical\" . filters ( list[str] | None ): A list of filters applied to filter objects based on their name. A filter starting with ! will exclude matching objects instead of including them. The members option takes precedence over filters (filters will still be applied recursively to lower members in the hierarchy). Default: [\"!^_[^_]\"] . group_by_category ( bool ): Group the object's children by categories: attributes, classes, functions, and modules. Default: True . Docstrings options: docstring_style ( str ): The docstring style to use: google , numpy , sphinx , or None . Default: \"google\" . docstring_options ( dict ): The options for the docstring parser. See parsers under pytkdocs.parsers.docstrings . show_if_no_docstring ( bool ): Show the object heading even if it has no docstring or children with docstrings. Default: False . Signatures/annotations options: show_signature ( bool ): Show methods and functions signatures. Default: True . show_signature_annotations ( bool ): Show the type annotations in methods and functions signatures. Default: False . Additional options: show_bases ( bool ): Show the base classes of a class. Default: True . show_source ( bool ): Show the source code of this object. Default: True . Supported docstrings styles \u00a4 Right now, pytkdocs supports the Google-style, Numpy-style and reStructuredText-style docstring formats. The style used by default is the Google-style. You can configure what style you want to use with the docstring_style and docstring_options options, both globally or per autodoc instruction. Google-style \u00a4 You can see examples of Google-style docstrings in Napoleon's documentation . Sections \u00a4 Docstrings sections are parsed by pytkdocs and rendered by mkdocstrings . Supported sections are: Arguments (or Args , Parameters , Params ) Attributes Examples (or Example ) Raises (or Raise , Except , Exceptions ) Returns (or Return ) Admonitions \u00a4 Additionally, any section that is not recognized will be transformed into its admonition equivalent. For example: Original Modified Result \"\"\" Note: You can disable this behavior with the `replace_admonitions` option. To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" \"\"\" !!! note \"You can disable this behavior with the `replace_admonitions` option.\" To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" You can disable this behavior with the replace_admonitions parser option To prevent pytkdocs from converting sections to admonitions, use the replace_admonitions parser option: ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no So meta! As shown in the above example, this can be disabled with the replace_admonitions option of the Google-style parser: :: : my_package.my_module selection : docstring_style : google # this is the default docstring_options : replace_admonitions : no Annotations \u00a4 Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Parameters: Name Type Description Default param1 int An integer? required param2 Optional[str] A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! None Source code in snippets/function_annotations_google.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Arguments: param1: An integer? param2: A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! \"\"\" return f \" { param2 }{ param1 } \" Numpy-style \u00a4 Extra dependency required You'll need an extra dependency to parse Numpy-style docstrings: pdm add -d --group docs 'pytkdocs[numpy-style]' poetry add -D 'pytkdocs[numpy-style]' pip install 'pytkdocs[numpy-style]' # etc. Note As Numpy-style is partially supported by the underlying parser, you may experience problems in the building process if your docstring has a Methods section in the class docstring (see #366 ). You can see examples of Numpy-style docstrings in numpydoc's documentation . reStructuredText-style \u00a4 Partial support Only RST- style is supported, not the whole RST markup specification. You can see examples of reStructuredText-style docstrings in Sphinx's documentation . Sections \u00a4 Docstrings directives are parsed by pytkdocs and rendered by mkdocstrings . Supported directives are: param (or parameter , arg , argument , key , keyword ) type raises (or raise , except , exception ) var (or ivar , cvar ) vartype returns (or return1 ) rtype Details about how to use each directive can be found in the Sphinx domain documentation Annotations \u00a4 Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Complex markup is supported in the main description section. I'm a code block! :param param1: An integer? :param param2: A string? If you have a long description, you can split it on multiple lines. Source code in snippets/function_annotations_rst.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Complex markup is supported in the main description section. I'm a code block! :param param1: An integer? :param param2: A string? If you have a long description, you can split it on multiple lines. \"\"\" return f \" { param2 }{ param1 } \" Finding modules \u00a4 There are multiple ways to tell the handler where to find your packages/modules. The recommended method is to use the paths option, as it's the only one that works with the -f option of MkDocs, allowing to build the documentation from any location on the file system. Indeed, the paths provided with the paths option are computed as relative to the configuration file (mkdocs.yml), so that the current working directory has no impact on the build process: you can build the docs from any location on your filesystem . Using the paths option \u00a4 This is the recommended method mkdocs.yml in root, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ . ] # actually not needed, default mkdocs.yml in root, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ src ] mkdocs.yml in subfolder, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ .. ] mkdocs.yml in subfolder, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ ../src ] Except for case 1, which is supported by default, we strongly recommend to set the path to your packages using this option, even if it works without it (for example because your project manager automatically adds src to PYTHONPATH), to make sure anyone can build your docs from any location on their filesystem. Behind the scenes, the handler will actually insert the specified paths in front of sys.path . Using the PYTHONPATH environment variable \u00a4 This method has limitations This method might work for you, with your current setup, but not for others trying your build your docs with their own setup/environment. We recommend to use the paths method instead. You can take advantage of the usual Python loading mechanisms. In Bash and other shells, you can run your command like this (note the prepended PYTHONPATH=... ): mkdocs.yml in root, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = . mkdocs build # actually not needed, default mkdocs.yml in root, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = src mkdocs build mkdocs.yml in subfolder, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = . mkdocs build -f docs/mkdocs.yml mkdocs.yml in subfolder, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = src mkdocs build -f docs/mkdocs.yml Installing your package in the current Python environment \u00a4 This method has limitations This method might work for you, with your current setup, but not for others trying your build your docs with their own setup/environment. We recommend to use the paths method instead. Install your package in the current environment, and run MkDocs: pip PDM Poetry . venv/bin/activate pip install -e . mkdocs build pdm install pdm run mkdocs build poetry install poetry run mkdocs build Using the setup commands \u00a4 This method has limitations This method might work for you, with your current setup, but not for others trying your build your docs with their own setup/environment. We recommend to use the paths method instead. You can use the setup commands to modify sys.path : mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - sys.path.append(\"src\") # or sys.path.insert(0, \"src\") Mocking libraries \u00a4 You may want to generate documentation for a package while its dependencies are not available. The Python handler provides itself no builtin way to mock libraries, but you can use the setup_commands to mock them manually: mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - from unittest.mock import MagicMock as mock - sys.modules[\"lib1\"] = mock() - sys.modules[\"lib2\"] = mock() - sys.modules[\"lib2.module1\"] = mock() - sys.modules[\"lib2.module1.moduleB\"] = mock() # etc Recommended style (Material) \u00a4 Here are some CSS rules for the Material for MkDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : .05 rem solid var ( --md-typeset-table-color ); } Recommended style (ReadTheDocs) \u00a4 Here are some CSS rules for the built-in ReadTheDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : 4 px solid rgba ( 230 , 230 , 230 ); }","title":"Usage"},{"location":"usage/#usage","text":"This is the documentation for the LEGACY Python handler To read the documentation for the NEW handler, go to the new handler documentation . The tool used by the legacy Python handler to collect documentation from Python source code is pytkdocs . It stands for (Python) Take Docs , and is supposed to be a pun on MkDocs ( Make Docs ?). Like every handler, the legacy Python handler accepts both global and local options.","title":"Usage"},{"location":"usage/#global-only-options","text":"Some options are global only , and go directly under the handler's name. import : this option is used to import Sphinx-compatible objects inventories from other documentation sites. For example, you can import the standard library objects inventory like this: mkdocs.yml plugins : - mkdocstrings : handlers : python : import : - https://docs.python-requests.org/en/master/objects.inv When importing an inventory, you enable automatic cross-references to other documentation sites like the standard library docs or any third-party package docs. Typically, you want to import the inventories of your project's dependencies, at least those that are used in the public API. Note This global option is common to all handlers, however they might implement it differently (or not even implement it). paths : this option is used to provide filesystem paths in which to search for Python modules. Non-absolute paths are computed as relative to MkDocs configuration file. Example: mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ src ] # search packages in the src folder More details at Finding modules . setup_commands : this option is used to instruct pytkdocs , the tool responsible for collecting data from sources, to run Python statements before starting to collect data. It is declared as a list of strings: mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import os - import django - os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"my_django_app.settings\") - django.setup() The setup commands are executed only once, when the pytkdocs background process is started.","title":"Global-only options"},{"location":"usage/#globallocal-options","text":"The other options can be used both globally and locally, under the options key. For example, globally: mkdocs.yml plugins : - mkdocstrings : handlers : python : options : do_something : true ...and locally, overriding the global configuration: docs/some_page.md ::: package.module.class options: do_something: false These options affect how the documentation is collected from sources and renderered: headings, members, docstrings, etc. Headings options: heading_level ( int ): The initial heading level to use. Default: 2 . show_root_heading ( bool ): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after ::: ). Default: False . show_root_toc_entry ( bool ): If the root heading is not shown, at least add a ToC entry for it. Default: True . show_root_full_path ( bool ): Show the full Python path for the root object heading. Default: True . show_root_members_full_path ( bool ): Show the full Python path of the root members. Default: False . show_object_full_path ( bool ): Show the full Python path of every object. Default: False . show_category_heading ( bool ): When grouped by categories, show a heading for each category. Default: False . Members options: members ( list[str] | False | None ): An explicit list of members to render. Default: None . members_order ( str ): The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. Default: \"alphabetical\" . filters ( list[str] | None ): A list of filters applied to filter objects based on their name. A filter starting with ! will exclude matching objects instead of including them. The members option takes precedence over filters (filters will still be applied recursively to lower members in the hierarchy). Default: [\"!^_[^_]\"] . group_by_category ( bool ): Group the object's children by categories: attributes, classes, functions, and modules. Default: True . Docstrings options: docstring_style ( str ): The docstring style to use: google , numpy , sphinx , or None . Default: \"google\" . docstring_options ( dict ): The options for the docstring parser. See parsers under pytkdocs.parsers.docstrings . show_if_no_docstring ( bool ): Show the object heading even if it has no docstring or children with docstrings. Default: False . Signatures/annotations options: show_signature ( bool ): Show methods and functions signatures. Default: True . show_signature_annotations ( bool ): Show the type annotations in methods and functions signatures. Default: False . Additional options: show_bases ( bool ): Show the base classes of a class. Default: True . show_source ( bool ): Show the source code of this object. Default: True .","title":"Global/local options"},{"location":"usage/#supported-docstrings-styles","text":"Right now, pytkdocs supports the Google-style, Numpy-style and reStructuredText-style docstring formats. The style used by default is the Google-style. You can configure what style you want to use with the docstring_style and docstring_options options, both globally or per autodoc instruction.","title":"Supported docstrings styles"},{"location":"usage/#google-style","text":"You can see examples of Google-style docstrings in Napoleon's documentation .","title":"Google-style"},{"location":"usage/#sections","text":"Docstrings sections are parsed by pytkdocs and rendered by mkdocstrings . Supported sections are: Arguments (or Args , Parameters , Params ) Attributes Examples (or Example ) Raises (or Raise , Except , Exceptions ) Returns (or Return )","title":"Sections"},{"location":"usage/#admonitions","text":"Additionally, any section that is not recognized will be transformed into its admonition equivalent. For example: Original Modified Result \"\"\" Note: You can disable this behavior with the `replace_admonitions` option. To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" \"\"\" !!! note \"You can disable this behavior with the `replace_admonitions` option.\" To prevent `pytkdocs` from converting sections to admonitions, use the `replace_admonitions`: ```md ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no ``` So meta! \"\"\" You can disable this behavior with the replace_admonitions parser option To prevent pytkdocs from converting sections to admonitions, use the replace_admonitions parser option: ::: my_package.my_module selection: docstring_style: google # this is the default docstring_options: replace_admonitions: no So meta! As shown in the above example, this can be disabled with the replace_admonitions option of the Google-style parser: :: : my_package.my_module selection : docstring_style : google # this is the default docstring_options : replace_admonitions : no","title":"Admonitions"},{"location":"usage/#annotations","text":"Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Parameters: Name Type Description Default param1 int An integer? required param2 Optional[str] A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! None Source code in snippets/function_annotations_google.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Arguments: param1: An integer? param2: A string? If you have a long description, you can split it on multiple lines. Just remember to indent those lines consistently. Complex markup is supported in sections items. I'm a code block! \"\"\" return f \" { param2 }{ param1 } \"","title":"Annotations"},{"location":"usage/#numpy-style","text":"Extra dependency required You'll need an extra dependency to parse Numpy-style docstrings: pdm add -d --group docs 'pytkdocs[numpy-style]' poetry add -D 'pytkdocs[numpy-style]' pip install 'pytkdocs[numpy-style]' # etc. Note As Numpy-style is partially supported by the underlying parser, you may experience problems in the building process if your docstring has a Methods section in the class docstring (see #366 ). You can see examples of Numpy-style docstrings in numpydoc's documentation .","title":"Numpy-style"},{"location":"usage/#restructuredtext-style","text":"Partial support Only RST- style is supported, not the whole RST markup specification. You can see examples of reStructuredText-style docstrings in Sphinx's documentation .","title":"reStructuredText-style"},{"location":"usage/#sections_1","text":"Docstrings directives are parsed by pytkdocs and rendered by mkdocstrings . Supported directives are: param (or parameter , arg , argument , key , keyword ) type raises (or raise , except , exception ) var (or ivar , cvar ) vartype returns (or return1 ) rtype Details about how to use each directive can be found in the Sphinx domain documentation","title":"Sections"},{"location":"usage/#annotations_1","text":"Type annotations are read both in the code and in the docstrings. Example with a function Expand the source at the end to see the original code! A short description of this function. Complex markup is supported in the main description section. I'm a code block! :param param1: An integer? :param param2: A string? If you have a long description, you can split it on multiple lines. Source code in snippets/function_annotations_rst.py def my_function ( param1 : int , param2 : Optional [ str ] = None ) -> str : \"\"\"A short description of this function. Complex markup is supported in the main description section. I'm a code block! :param param1: An integer? :param param2: A string? If you have a long description, you can split it on multiple lines. \"\"\" return f \" { param2 }{ param1 } \"","title":"Annotations"},{"location":"usage/#finding-modules","text":"There are multiple ways to tell the handler where to find your packages/modules. The recommended method is to use the paths option, as it's the only one that works with the -f option of MkDocs, allowing to build the documentation from any location on the file system. Indeed, the paths provided with the paths option are computed as relative to the configuration file (mkdocs.yml), so that the current working directory has no impact on the build process: you can build the docs from any location on your filesystem .","title":"Finding modules"},{"location":"usage/#using-the-paths-option","text":"This is the recommended method mkdocs.yml in root, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ . ] # actually not needed, default mkdocs.yml in root, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ src ] mkdocs.yml in subfolder, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ .. ] mkdocs.yml in subfolder, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ mkdocs.yml plugins : - mkdocstrings : handlers : python : paths : [ ../src ] Except for case 1, which is supported by default, we strongly recommend to set the path to your packages using this option, even if it works without it (for example because your project manager automatically adds src to PYTHONPATH), to make sure anyone can build your docs from any location on their filesystem. Behind the scenes, the handler will actually insert the specified paths in front of sys.path .","title":"Using the paths option"},{"location":"usage/#using-the-pythonpath-environment-variable","text":"This method has limitations This method might work for you, with your current setup, but not for others trying your build your docs with their own setup/environment. We recommend to use the paths method instead. You can take advantage of the usual Python loading mechanisms. In Bash and other shells, you can run your command like this (note the prepended PYTHONPATH=... ): mkdocs.yml in root, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = . mkdocs build # actually not needed, default mkdocs.yml in root, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = src mkdocs build mkdocs.yml in subfolder, package in root \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = . mkdocs build -f docs/mkdocs.yml mkdocs.yml in subfolder, package in subfolder \ud83d\udcc1 root/ \u251c\u2500\u2500 \ud83d\udcc1 docs/ \u2502 \u2514\u2500\u2500 \ud83d\udcc4 mkdocs.yml \u2514\u2500\u2500 \ud83d\udcc1 src/ \u2514\u2500\u2500 \ud83d\udcc1 package/ PYTHONPATH = src mkdocs build -f docs/mkdocs.yml","title":"Using the PYTHONPATH environment variable"},{"location":"usage/#installing-your-package-in-the-current-python-environment","text":"This method has limitations This method might work for you, with your current setup, but not for others trying your build your docs with their own setup/environment. We recommend to use the paths method instead. Install your package in the current environment, and run MkDocs: pip PDM Poetry . venv/bin/activate pip install -e . mkdocs build pdm install pdm run mkdocs build poetry install poetry run mkdocs build","title":"Installing your package in the current Python environment"},{"location":"usage/#using-the-setup-commands","text":"This method has limitations This method might work for you, with your current setup, but not for others trying your build your docs with their own setup/environment. We recommend to use the paths method instead. You can use the setup commands to modify sys.path : mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - sys.path.append(\"src\") # or sys.path.insert(0, \"src\")","title":"Using the setup commands"},{"location":"usage/#mocking-libraries","text":"You may want to generate documentation for a package while its dependencies are not available. The Python handler provides itself no builtin way to mock libraries, but you can use the setup_commands to mock them manually: mkdocs.yml plugins : - mkdocstrings : handlers : python : setup_commands : - import sys - from unittest.mock import MagicMock as mock - sys.modules[\"lib1\"] = mock() - sys.modules[\"lib2\"] = mock() - sys.modules[\"lib2.module1\"] = mock() - sys.modules[\"lib2.module1.moduleB\"] = mock() # etc","title":"Mocking libraries"},{"location":"usage/#recommended-style-material","text":"Here are some CSS rules for the Material for MkDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : .05 rem solid var ( --md-typeset-table-color ); }","title":"Recommended style (Material)"},{"location":"usage/#recommended-style-readthedocs","text":"Here are some CSS rules for the built-in ReadTheDocs theme: /* Indentation. */ div . doc-contents : not ( . first ) { padding-left : 25 px ; border-left : 4 px solid rgba ( 230 , 230 , 230 ); }","title":"Recommended style (ReadTheDocs)"},{"location":"reference/SUMMARY/","text":"mkdocstrings_handlers python handler rendering","title":"SUMMARY"},{"location":"reference/mkdocstrings_handlers/python/","text":"This package implements a handler for the Python language. handler \u00a4 This module implements a handler for the Python language. It collects data with pytkdocs . PythonHandler ( BaseHandler ) \u00a4 The Python handler class. Attributes: Name Type Description domain str The cross-documentation domain/language for this handler. enable_inventory bool Whether this handler is interested in enabling the creation of the objects.inv Sphinx inventory file. Source code in python/handler.py class PythonHandler ( BaseHandler ): \"\"\"The Python handler class. Attributes: domain: The cross-documentation domain/language for this handler. enable_inventory: Whether this handler is interested in enabling the creation of the `objects.inv` Sphinx inventory file. \"\"\" domain : str = \"py\" # to match Sphinx's default domain enable_inventory : bool = True fallback_theme = \"material\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ], \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\" **Headings options:** - `heading_level` (`int`): The initial heading level to use. Default: `2`. - `show_root_heading` (`bool`): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after `:::`). Default: `False`. - `show_root_toc_entry` (`bool`): If the root heading is not shown, at least add a ToC entry for it. Default: `True`. - `show_root_full_path` (`bool`): Show the full Python path for the root object heading. Default: `True`. - `show_root_members_full_path` (`bool`): Show the full Python path of the root members. Default: `False`. - `show_object_full_path` (`bool`): Show the full Python path of every object. Default: `False`. - `show_category_heading` (`bool`): When grouped by categories, show a heading for each category. Default: `False`. **Members options:** - `members` (`list[str] | False | None`): An explicit list of members to render. Default: `None`. - `members_order` (`str`): The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. Default: `\"alphabetical\"`. - `filters` (`list[str] | None`): A list of filters applied to filter objects based on their name. A filter starting with `!` will exclude matching objects instead of including them. The `members` option takes precedence over `filters` (filters will still be applied recursively to lower members in the hierarchy). Default: `[\"!^_[^_]\"]`. - `group_by_category` (`bool`): Group the object's children by categories: attributes, classes, functions, and modules. Default: `True`. **Docstrings options:** - `docstring_style` (`str`): The docstring style to use: `google`, `numpy`, `sphinx`, or `None`. Default: `\"google\"`. - `docstring_options` (`dict`): The options for the docstring parser. See parsers under [`pytkdocs.parsers.docstrings`][]. - `show_if_no_docstring` (`bool`): Show the object heading even if it has no docstring or children with docstrings. Default: `False`. **Signatures/annotations options:** - `show_signature` (`bool`): Show methods and functions signatures. Default: `True`. - `show_signature_annotations` (`bool`): Show the type annotations in methods and functions signatures. Default: `False`. **Additional options:** - `show_bases` (`bool`): Show the base classes of a class. Default: `True`. - `show_source` (`bool`): Show the source code of this object. Default: `True`. \"\"\" # noqa: E501 def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs ) @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate () def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref default_config : dict \u00a4 Headings options: heading_level ( int ): The initial heading level to use. Default: 2 . show_root_heading ( bool ): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after ::: ). Default: False . show_root_toc_entry ( bool ): If the root heading is not shown, at least add a ToC entry for it. Default: True . show_root_full_path ( bool ): Show the full Python path for the root object heading. Default: True . show_root_members_full_path ( bool ): Show the full Python path of the root members. Default: False . show_object_full_path ( bool ): Show the full Python path of every object. Default: False . show_category_heading ( bool ): When grouped by categories, show a heading for each category. Default: False . Members options: members ( list[str] | False | None ): An explicit list of members to render. Default: None . members_order ( str ): The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. Default: \"alphabetical\" . filters ( list[str] | None ): A list of filters applied to filter objects based on their name. A filter starting with ! will exclude matching objects instead of including them. The members option takes precedence over filters (filters will still be applied recursively to lower members in the hierarchy). Default: [\"!^_[^_]\"] . group_by_category ( bool ): Group the object's children by categories: attributes, classes, functions, and modules. Default: True . Docstrings options: docstring_style ( str ): The docstring style to use: google , numpy , sphinx , or None . Default: \"google\" . docstring_options ( dict ): The options for the docstring parser. See parsers under pytkdocs.parsers.docstrings . show_if_no_docstring ( bool ): Show the object heading even if it has no docstring or children with docstrings. Default: False . Signatures/annotations options: show_signature ( bool ): Show methods and functions signatures. Default: True . show_signature_annotations ( bool ): Show the type annotations in methods and functions signatures. Default: False . Additional options: show_bases ( bool ): Show the base classes of a class. Default: True . show_source ( bool ): Show the source code of this object. Default: True . fallback_config : dict \u00a4 The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. __init__ ( self , * args , * , setup_commands = None , config_file_path = None , paths = None , ** kwargs ) special \u00a4 Initialize the handler. When instantiating a Python handler, we open a pytkdocs subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default *args Handler name, theme and custom templates. () setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None **kwargs Same thing, but with keyword arguments. {} Source code in python/handler.py def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs ) collect ( self , identifier , config ) \u00a4 Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description CollectorItem The collected object-tree. Source code in python/handler.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result get_anchors ( self , data ) \u00a4 Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data CollectorItem The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/handler.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () load_inventory ( in_file , url , base_url = None , ** kwargs ) classmethod \u00a4 Yield items and their URLs from an inventory file streamed from in_file . This implements mkdocstrings' load_inventory \"protocol\" (see plugin.py). Parameters: Name Type Description Default in_file BinaryIO The binary file-like object to read the inventory from. required url str The URL that this file is being streamed from (used to guess base_url ). required base_url Optional[str] The URL that this inventory's sub-paths are relative to. None **kwargs Ignore additional arguments passed from the config. {} Yields: Type Description Iterator[Tuple[str, str]] Tuples of (item identifier, item URL). Source code in python/handler.py @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) render ( self , data , config ) \u00a4 Render a template using provided data and configuration options. Parameters: Name Type Description Default data CollectorItem The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/handler.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) teardown ( self ) \u00a4 Terminate the opened subprocess, set it to None . Source code in python/handler.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate () update_env ( self , md , config ) \u00a4 Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/handler.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref get_handler ( theme , custom_templates = None , setup_commands = None , config_file_path = None , paths = None , ** config ) \u00a4 Simply return an instance of PythonHandler . Parameters: Name Type Description Default theme str The theme to use when rendering contents. required custom_templates Optional[str] Directory containing custom templates. None setup_commands Optional[List[str]] A list of commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None config Any Configuration passed to the handler. {} Returns: Type Description PythonHandler An instance of PythonHandler . Source code in python/handler.py def get_handler ( theme : str , # noqa: W0613 (unused argument config) custom_templates : Optional [ str ] = None , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** config : Any , ) -> PythonHandler : \"\"\"Simply return an instance of `PythonHandler`. Arguments: theme: The theme to use when rendering contents. custom_templates: Directory containing custom templates. setup_commands: A list of commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. config: Configuration passed to the handler. Returns: An instance of `PythonHandler`. \"\"\" return PythonHandler ( handler = \"python\" , theme = theme , custom_templates = custom_templates , setup_commands = setup_commands , config_file_path = config_file_path , paths = paths , ) rendering \u00a4 This module implements rendering utilities. do_brief_xref ( path ) \u00a4 Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/rendering.py def do_brief_xref ( path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief ) rebuild_category_lists ( obj ) \u00a4 Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/rendering.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child ) sort_key_alphabetical ( item ) \u00a4 Return an item's name or the final unicode character. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Name or final unicode character. Source code in python/rendering.py def sort_key_alphabetical ( item : CollectorItem ) -> Any : \"\"\"Return an item's name or the final unicode character. Arguments: item: A collected item. Returns: Name or final unicode character. \"\"\" # chr(sys.maxunicode) is a string that contains the final unicode # character, so if 'name' isn't found on the object, the item will go to # the end of the list. return item . get ( \"name\" , chr ( sys . maxunicode )) sort_key_source ( item ) \u00a4 Return an item's starting line number or -1. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Starting line number or -1. Source code in python/rendering.py def sort_key_source ( item : CollectorItem ) -> Any : \"\"\"Return an item's starting line number or -1. Arguments: item: A collected item. Returns: Starting line number or -1. \"\"\" # if 'line_start' isn't found on the object, the item will go to # the start of the list. return item . get ( \"source\" , {}) . get ( \"line_start\" , - 1 ) sort_object ( obj , sort_function ) \u00a4 Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj CollectorItem The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[CollectorItem], Any] The sort key function used to determine the order of elements. required Source code in python/rendering.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"python"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler","text":"This module implements a handler for the Python language. It collects data with pytkdocs .","title":"handler"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler","text":"The Python handler class. Attributes: Name Type Description domain str The cross-documentation domain/language for this handler. enable_inventory bool Whether this handler is interested in enabling the creation of the objects.inv Sphinx inventory file. Source code in python/handler.py class PythonHandler ( BaseHandler ): \"\"\"The Python handler class. Attributes: domain: The cross-documentation domain/language for this handler. enable_inventory: Whether this handler is interested in enabling the creation of the `objects.inv` Sphinx inventory file. \"\"\" domain : str = \"py\" # to match Sphinx's default domain enable_inventory : bool = True fallback_theme = \"material\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ], \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\" **Headings options:** - `heading_level` (`int`): The initial heading level to use. Default: `2`. - `show_root_heading` (`bool`): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after `:::`). Default: `False`. - `show_root_toc_entry` (`bool`): If the root heading is not shown, at least add a ToC entry for it. Default: `True`. - `show_root_full_path` (`bool`): Show the full Python path for the root object heading. Default: `True`. - `show_root_members_full_path` (`bool`): Show the full Python path of the root members. Default: `False`. - `show_object_full_path` (`bool`): Show the full Python path of every object. Default: `False`. - `show_category_heading` (`bool`): When grouped by categories, show a heading for each category. Default: `False`. **Members options:** - `members` (`list[str] | False | None`): An explicit list of members to render. Default: `None`. - `members_order` (`str`): The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. Default: `\"alphabetical\"`. - `filters` (`list[str] | None`): A list of filters applied to filter objects based on their name. A filter starting with `!` will exclude matching objects instead of including them. The `members` option takes precedence over `filters` (filters will still be applied recursively to lower members in the hierarchy). Default: `[\"!^_[^_]\"]`. - `group_by_category` (`bool`): Group the object's children by categories: attributes, classes, functions, and modules. Default: `True`. **Docstrings options:** - `docstring_style` (`str`): The docstring style to use: `google`, `numpy`, `sphinx`, or `None`. Default: `\"google\"`. - `docstring_options` (`dict`): The options for the docstring parser. See parsers under [`pytkdocs.parsers.docstrings`][]. - `show_if_no_docstring` (`bool`): Show the object heading even if it has no docstring or children with docstrings. Default: `False`. **Signatures/annotations options:** - `show_signature` (`bool`): Show methods and functions signatures. Default: `True`. - `show_signature_annotations` (`bool`): Show the type annotations in methods and functions signatures. Default: `False`. **Additional options:** - `show_bases` (`bool`): Show the base classes of a class. Default: `True`. - `show_source` (`bool`): Show the source code of this object. Default: `True`. \"\"\" # noqa: E501 def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs ) @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate () def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref","title":"PythonHandler"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.default_config","text":"Headings options: heading_level ( int ): The initial heading level to use. Default: 2 . show_root_heading ( bool ): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after ::: ). Default: False . show_root_toc_entry ( bool ): If the root heading is not shown, at least add a ToC entry for it. Default: True . show_root_full_path ( bool ): Show the full Python path for the root object heading. Default: True . show_root_members_full_path ( bool ): Show the full Python path of the root members. Default: False . show_object_full_path ( bool ): Show the full Python path of every object. Default: False . show_category_heading ( bool ): When grouped by categories, show a heading for each category. Default: False . Members options: members ( list[str] | False | None ): An explicit list of members to render. Default: None . members_order ( str ): The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. Default: \"alphabetical\" . filters ( list[str] | None ): A list of filters applied to filter objects based on their name. A filter starting with ! will exclude matching objects instead of including them. The members option takes precedence over filters (filters will still be applied recursively to lower members in the hierarchy). Default: [\"!^_[^_]\"] . group_by_category ( bool ): Group the object's children by categories: attributes, classes, functions, and modules. Default: True . Docstrings options: docstring_style ( str ): The docstring style to use: google , numpy , sphinx , or None . Default: \"google\" . docstring_options ( dict ): The options for the docstring parser. See parsers under pytkdocs.parsers.docstrings . show_if_no_docstring ( bool ): Show the object heading even if it has no docstring or children with docstrings. Default: False . Signatures/annotations options: show_signature ( bool ): Show methods and functions signatures. Default: True . show_signature_annotations ( bool ): Show the type annotations in methods and functions signatures. Default: False . Additional options: show_bases ( bool ): Show the base classes of a class. Default: True . show_source ( bool ): Show the source code of this object. Default: True .","title":"default_config"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.fallback_config","text":"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings.","title":"fallback_config"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.__init__","text":"Initialize the handler. When instantiating a Python handler, we open a pytkdocs subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default *args Handler name, theme and custom templates. () setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None **kwargs Same thing, but with keyword arguments. {} Source code in python/handler.py def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs )","title":"__init__()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.collect","text":"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description CollectorItem The collected object-tree. Source code in python/handler.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result","title":"collect()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.get_anchors","text":"Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data CollectorItem The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/handler.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return ()","title":"get_anchors()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.load_inventory","text":"Yield items and their URLs from an inventory file streamed from in_file . This implements mkdocstrings' load_inventory \"protocol\" (see plugin.py). Parameters: Name Type Description Default in_file BinaryIO The binary file-like object to read the inventory from. required url str The URL that this file is being streamed from (used to guess base_url ). required base_url Optional[str] The URL that this inventory's sub-paths are relative to. None **kwargs Ignore additional arguments passed from the config. {} Yields: Type Description Iterator[Tuple[str, str]] Tuples of (item identifier, item URL). Source code in python/handler.py @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri )","title":"load_inventory()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.render","text":"Render a template using provided data and configuration options. Parameters: Name Type Description Default data CollectorItem The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/handler.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, )","title":"render()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.teardown","text":"Terminate the opened subprocess, set it to None . Source code in python/handler.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate ()","title":"teardown()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.PythonHandler.update_env","text":"Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/handler.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref","title":"update_env()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.handler.get_handler","text":"Simply return an instance of PythonHandler . Parameters: Name Type Description Default theme str The theme to use when rendering contents. required custom_templates Optional[str] Directory containing custom templates. None setup_commands Optional[List[str]] A list of commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None config Any Configuration passed to the handler. {} Returns: Type Description PythonHandler An instance of PythonHandler . Source code in python/handler.py def get_handler ( theme : str , # noqa: W0613 (unused argument config) custom_templates : Optional [ str ] = None , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** config : Any , ) -> PythonHandler : \"\"\"Simply return an instance of `PythonHandler`. Arguments: theme: The theme to use when rendering contents. custom_templates: Directory containing custom templates. setup_commands: A list of commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. config: Configuration passed to the handler. Returns: An instance of `PythonHandler`. \"\"\" return PythonHandler ( handler = \"python\" , theme = theme , custom_templates = custom_templates , setup_commands = setup_commands , config_file_path = config_file_path , paths = paths , )","title":"get_handler()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.rendering","text":"This module implements rendering utilities.","title":"rendering"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.rendering.do_brief_xref","text":"Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/rendering.py def do_brief_xref ( path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief )","title":"do_brief_xref()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.rendering.rebuild_category_lists","text":"Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/rendering.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child )","title":"rebuild_category_lists()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.rendering.sort_key_alphabetical","text":"Return an item's name or the final unicode character. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Name or final unicode character. Source code in python/rendering.py def sort_key_alphabetical ( item : CollectorItem ) -> Any : \"\"\"Return an item's name or the final unicode character. Arguments: item: A collected item. Returns: Name or final unicode character. \"\"\" # chr(sys.maxunicode) is a string that contains the final unicode # character, so if 'name' isn't found on the object, the item will go to # the end of the list. return item . get ( \"name\" , chr ( sys . maxunicode ))","title":"sort_key_alphabetical()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.rendering.sort_key_source","text":"Return an item's starting line number or -1. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Starting line number or -1. Source code in python/rendering.py def sort_key_source ( item : CollectorItem ) -> Any : \"\"\"Return an item's starting line number or -1. Arguments: item: A collected item. Returns: Starting line number or -1. \"\"\" # if 'line_start' isn't found on the object, the item will go to # the start of the list. return item . get ( \"source\" , {}) . get ( \"line_start\" , - 1 )","title":"sort_key_source()"},{"location":"reference/mkdocstrings_handlers/python/#mkdocstrings_handlers.python.rendering.sort_object","text":"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj CollectorItem The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[CollectorItem], Any] The sort key function used to determine the order of elements. required Source code in python/rendering.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"sort_object()"},{"location":"reference/mkdocstrings_handlers/python/handler/","text":"This module implements a handler for the Python language. It collects data with pytkdocs . PythonHandler ( BaseHandler ) \u00a4 The Python handler class. Attributes: Name Type Description domain str The cross-documentation domain/language for this handler. enable_inventory bool Whether this handler is interested in enabling the creation of the objects.inv Sphinx inventory file. Source code in python/handler.py class PythonHandler ( BaseHandler ): \"\"\"The Python handler class. Attributes: domain: The cross-documentation domain/language for this handler. enable_inventory: Whether this handler is interested in enabling the creation of the `objects.inv` Sphinx inventory file. \"\"\" domain : str = \"py\" # to match Sphinx's default domain enable_inventory : bool = True fallback_theme = \"material\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ], \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\" **Headings options:** - `heading_level` (`int`): The initial heading level to use. Default: `2`. - `show_root_heading` (`bool`): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after `:::`). Default: `False`. - `show_root_toc_entry` (`bool`): If the root heading is not shown, at least add a ToC entry for it. Default: `True`. - `show_root_full_path` (`bool`): Show the full Python path for the root object heading. Default: `True`. - `show_root_members_full_path` (`bool`): Show the full Python path of the root members. Default: `False`. - `show_object_full_path` (`bool`): Show the full Python path of every object. Default: `False`. - `show_category_heading` (`bool`): When grouped by categories, show a heading for each category. Default: `False`. **Members options:** - `members` (`list[str] | False | None`): An explicit list of members to render. Default: `None`. - `members_order` (`str`): The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. Default: `\"alphabetical\"`. - `filters` (`list[str] | None`): A list of filters applied to filter objects based on their name. A filter starting with `!` will exclude matching objects instead of including them. The `members` option takes precedence over `filters` (filters will still be applied recursively to lower members in the hierarchy). Default: `[\"!^_[^_]\"]`. - `group_by_category` (`bool`): Group the object's children by categories: attributes, classes, functions, and modules. Default: `True`. **Docstrings options:** - `docstring_style` (`str`): The docstring style to use: `google`, `numpy`, `sphinx`, or `None`. Default: `\"google\"`. - `docstring_options` (`dict`): The options for the docstring parser. See parsers under [`pytkdocs.parsers.docstrings`][]. - `show_if_no_docstring` (`bool`): Show the object heading even if it has no docstring or children with docstrings. Default: `False`. **Signatures/annotations options:** - `show_signature` (`bool`): Show methods and functions signatures. Default: `True`. - `show_signature_annotations` (`bool`): Show the type annotations in methods and functions signatures. Default: `False`. **Additional options:** - `show_bases` (`bool`): Show the base classes of a class. Default: `True`. - `show_source` (`bool`): Show the source code of this object. Default: `True`. \"\"\" # noqa: E501 def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs ) @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate () def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref default_config : dict \u00a4 Headings options: heading_level ( int ): The initial heading level to use. Default: 2 . show_root_heading ( bool ): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after ::: ). Default: False . show_root_toc_entry ( bool ): If the root heading is not shown, at least add a ToC entry for it. Default: True . show_root_full_path ( bool ): Show the full Python path for the root object heading. Default: True . show_root_members_full_path ( bool ): Show the full Python path of the root members. Default: False . show_object_full_path ( bool ): Show the full Python path of every object. Default: False . show_category_heading ( bool ): When grouped by categories, show a heading for each category. Default: False . Members options: members ( list[str] | False | None ): An explicit list of members to render. Default: None . members_order ( str ): The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. Default: \"alphabetical\" . filters ( list[str] | None ): A list of filters applied to filter objects based on their name. A filter starting with ! will exclude matching objects instead of including them. The members option takes precedence over filters (filters will still be applied recursively to lower members in the hierarchy). Default: [\"!^_[^_]\"] . group_by_category ( bool ): Group the object's children by categories: attributes, classes, functions, and modules. Default: True . Docstrings options: docstring_style ( str ): The docstring style to use: google , numpy , sphinx , or None . Default: \"google\" . docstring_options ( dict ): The options for the docstring parser. See parsers under pytkdocs.parsers.docstrings . show_if_no_docstring ( bool ): Show the object heading even if it has no docstring or children with docstrings. Default: False . Signatures/annotations options: show_signature ( bool ): Show methods and functions signatures. Default: True . show_signature_annotations ( bool ): Show the type annotations in methods and functions signatures. Default: False . Additional options: show_bases ( bool ): Show the base classes of a class. Default: True . show_source ( bool ): Show the source code of this object. Default: True . fallback_config : dict \u00a4 The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. __init__ ( self , * args , * , setup_commands = None , config_file_path = None , paths = None , ** kwargs ) special \u00a4 Initialize the handler. When instantiating a Python handler, we open a pytkdocs subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default *args Handler name, theme and custom templates. () setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None **kwargs Same thing, but with keyword arguments. {} Source code in python/handler.py def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs ) collect ( self , identifier , config ) \u00a4 Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description CollectorItem The collected object-tree. Source code in python/handler.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result get_anchors ( self , data ) \u00a4 Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data CollectorItem The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/handler.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () load_inventory ( in_file , url , base_url = None , ** kwargs ) classmethod \u00a4 Yield items and their URLs from an inventory file streamed from in_file . This implements mkdocstrings' load_inventory \"protocol\" (see plugin.py). Parameters: Name Type Description Default in_file BinaryIO The binary file-like object to read the inventory from. required url str The URL that this file is being streamed from (used to guess base_url ). required base_url Optional[str] The URL that this inventory's sub-paths are relative to. None **kwargs Ignore additional arguments passed from the config. {} Yields: Type Description Iterator[Tuple[str, str]] Tuples of (item identifier, item URL). Source code in python/handler.py @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) render ( self , data , config ) \u00a4 Render a template using provided data and configuration options. Parameters: Name Type Description Default data CollectorItem The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/handler.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) teardown ( self ) \u00a4 Terminate the opened subprocess, set it to None . Source code in python/handler.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate () update_env ( self , md , config ) \u00a4 Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/handler.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref get_handler ( theme , custom_templates = None , setup_commands = None , config_file_path = None , paths = None , ** config ) \u00a4 Simply return an instance of PythonHandler . Parameters: Name Type Description Default theme str The theme to use when rendering contents. required custom_templates Optional[str] Directory containing custom templates. None setup_commands Optional[List[str]] A list of commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None config Any Configuration passed to the handler. {} Returns: Type Description PythonHandler An instance of PythonHandler . Source code in python/handler.py def get_handler ( theme : str , # noqa: W0613 (unused argument config) custom_templates : Optional [ str ] = None , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** config : Any , ) -> PythonHandler : \"\"\"Simply return an instance of `PythonHandler`. Arguments: theme: The theme to use when rendering contents. custom_templates: Directory containing custom templates. setup_commands: A list of commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. config: Configuration passed to the handler. Returns: An instance of `PythonHandler`. \"\"\" return PythonHandler ( handler = \"python\" , theme = theme , custom_templates = custom_templates , setup_commands = setup_commands , config_file_path = config_file_path , paths = paths , )","title":"handler"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler","text":"The Python handler class. Attributes: Name Type Description domain str The cross-documentation domain/language for this handler. enable_inventory bool Whether this handler is interested in enabling the creation of the objects.inv Sphinx inventory file. Source code in python/handler.py class PythonHandler ( BaseHandler ): \"\"\"The Python handler class. Attributes: domain: The cross-documentation domain/language for this handler. enable_inventory: Whether this handler is interested in enabling the creation of the `objects.inv` Sphinx inventory file. \"\"\" domain : str = \"py\" # to match Sphinx's default domain enable_inventory : bool = True fallback_theme = \"material\" fallback_config = { \"docstring_style\" : \"markdown\" , \"filters\" : [ \"!.*\" ]} \"\"\"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in [`Handlers.get_anchors`][mkdocstrings.handlers.base.Handlers.get_anchors]. When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings. \"\"\" default_config : dict = { \"filters\" : [ \"!^_[^_]\" ], \"show_root_heading\" : False , \"show_root_toc_entry\" : True , \"show_root_full_path\" : True , \"show_root_members_full_path\" : False , \"show_object_full_path\" : False , \"show_category_heading\" : False , \"show_if_no_docstring\" : False , \"show_signature\" : True , \"show_signature_annotations\" : False , \"show_source\" : True , \"show_bases\" : True , \"group_by_category\" : True , \"heading_level\" : 2 , \"members_order\" : \"alphabetical\" , } \"\"\" **Headings options:** - `heading_level` (`int`): The initial heading level to use. Default: `2`. - `show_root_heading` (`bool`): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after `:::`). Default: `False`. - `show_root_toc_entry` (`bool`): If the root heading is not shown, at least add a ToC entry for it. Default: `True`. - `show_root_full_path` (`bool`): Show the full Python path for the root object heading. Default: `True`. - `show_root_members_full_path` (`bool`): Show the full Python path of the root members. Default: `False`. - `show_object_full_path` (`bool`): Show the full Python path of every object. Default: `False`. - `show_category_heading` (`bool`): When grouped by categories, show a heading for each category. Default: `False`. **Members options:** - `members` (`list[str] | False | None`): An explicit list of members to render. Default: `None`. - `members_order` (`str`): The members ordering to use. Options: `alphabetical` - order by the members names, `source` - order members as they appear in the source file. Default: `\"alphabetical\"`. - `filters` (`list[str] | None`): A list of filters applied to filter objects based on their name. A filter starting with `!` will exclude matching objects instead of including them. The `members` option takes precedence over `filters` (filters will still be applied recursively to lower members in the hierarchy). Default: `[\"!^_[^_]\"]`. - `group_by_category` (`bool`): Group the object's children by categories: attributes, classes, functions, and modules. Default: `True`. **Docstrings options:** - `docstring_style` (`str`): The docstring style to use: `google`, `numpy`, `sphinx`, or `None`. Default: `\"google\"`. - `docstring_options` (`dict`): The options for the docstring parser. See parsers under [`pytkdocs.parsers.docstrings`][]. - `show_if_no_docstring` (`bool`): Show the object heading even if it has no docstring or children with docstrings. Default: `False`. **Signatures/annotations options:** - `show_signature` (`bool`): Show methods and functions signatures. Default: `True`. - `show_signature_annotations` (`bool`): Show the type annotations in methods and functions signatures. Default: `False`. **Additional options:** - `show_bases` (`bool`): Show the base classes of a class. Default: `True`. - `show_source` (`bool`): Show the source code of this object. Default: `True`. \"\"\" # noqa: E501 def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs ) @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri ) def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate () def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, ) def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return () def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref","title":"PythonHandler"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.default_config","text":"Headings options: heading_level ( int ): The initial heading level to use. Default: 2 . show_root_heading ( bool ): Show the heading of the object at the root of the documentation tree (i.e. the object referenced by the identifier after ::: ). Default: False . show_root_toc_entry ( bool ): If the root heading is not shown, at least add a ToC entry for it. Default: True . show_root_full_path ( bool ): Show the full Python path for the root object heading. Default: True . show_root_members_full_path ( bool ): Show the full Python path of the root members. Default: False . show_object_full_path ( bool ): Show the full Python path of every object. Default: False . show_category_heading ( bool ): When grouped by categories, show a heading for each category. Default: False . Members options: members ( list[str] | False | None ): An explicit list of members to render. Default: None . members_order ( str ): The members ordering to use. Options: alphabetical - order by the members names, source - order members as they appear in the source file. Default: \"alphabetical\" . filters ( list[str] | None ): A list of filters applied to filter objects based on their name. A filter starting with ! will exclude matching objects instead of including them. The members option takes precedence over filters (filters will still be applied recursively to lower members in the hierarchy). Default: [\"!^_[^_]\"] . group_by_category ( bool ): Group the object's children by categories: attributes, classes, functions, and modules. Default: True . Docstrings options: docstring_style ( str ): The docstring style to use: google , numpy , sphinx , or None . Default: \"google\" . docstring_options ( dict ): The options for the docstring parser. See parsers under pytkdocs.parsers.docstrings . show_if_no_docstring ( bool ): Show the object heading even if it has no docstring or children with docstrings. Default: False . Signatures/annotations options: show_signature ( bool ): Show methods and functions signatures. Default: True . show_signature_annotations ( bool ): Show the type annotations in methods and functions signatures. Default: False . Additional options: show_bases ( bool ): Show the base classes of a class. Default: True . show_source ( bool ): Show the source code of this object. Default: True .","title":"default_config"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.fallback_config","text":"The configuration used when falling back to re-collecting an object to get its anchor. This configuration is used in Handlers.get_anchors . When trying to fix (optional) cross-references, the autorefs plugin will try to collect an object with every configured handler until one succeeds. It will then try to get an anchor for it. It's because objects can have multiple identifiers (aliases), for example their definition path and multiple import paths in Python. When re-collecting the object, we have no use for its members, or for its docstring being parsed. This is why the fallback configuration filters every member out, and uses the Markdown style, which we know will not generate any warnings.","title":"fallback_config"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.__init__","text":"Initialize the handler. When instantiating a Python handler, we open a pytkdocs subprocess in the background with subprocess.Popen . It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down mkdocstrings a lot. Parameters: Name Type Description Default *args Handler name, theme and custom templates. () setup_commands Optional[List[str]] A list of python commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None **kwargs Same thing, but with keyword arguments. {} Source code in python/handler.py def __init__ ( # noqa: WPS231 self , * args , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** kwargs , ) -> None : \"\"\"Initialize the handler. When instantiating a Python handler, we open a `pytkdocs` subprocess in the background with `subprocess.Popen`. It will allow us to feed input to and read output from this subprocess, keeping it alive during the whole documentation generation. Spawning a new Python subprocess for each \"autodoc\" instruction would be too resource intensive, and would slow down `mkdocstrings` a lot. Parameters: *args: Handler name, theme and custom templates. setup_commands: A list of python commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. **kwargs: Same thing, but with keyword arguments. \"\"\" logger . debug ( \"Opening 'pytkdocs' subprocess\" ) env = os . environ . copy () env [ \"PYTHONUNBUFFERED\" ] = \"1\" self . _config_file_path = config_file_path paths = paths or [] if not paths and config_file_path : paths . append ( os . path . dirname ( config_file_path )) search_paths = [] for path in paths : if not os . path . isabs ( path ): if config_file_path : path = os . path . abspath ( os . path . join ( os . path . dirname ( config_file_path ), path )) if path not in search_paths : search_paths . append ( path ) self . _paths = search_paths commands = [] if search_paths : commands . extend ([ f \"sys.path.insert(0, { path !r} )\" for path in reversed ( search_paths )]) # noqa: WPS441 if setup_commands : # prevent the Python interpreter or the setup commands # from writing to stdout as it would break pytkdocs output commands . extend ( [ \"from io import StringIO\" , \"sys.stdout = StringIO()\" , # redirect stdout to memory buffer * setup_commands , \"sys.stdout.flush()\" , \"sys.stdout = sys.__stdout__\" , # restore stdout ] ) if commands : final_commands = [ \"import sys\" , * commands , \"from pytkdocs.cli import main as pytkdocs\" , \"pytkdocs(['--line-by-line'])\" , ] cmd = [ sys . executable , \"-c\" , \"; \" . join ( final_commands )] else : cmd = [ sys . executable , \"-m\" , \"pytkdocs\" , \"--line-by-line\" ] self . process = Popen ( # noqa: S603,S607 (we trust the input, and we don't want to use the absolute path) cmd , universal_newlines = True , stdout = PIPE , stdin = PIPE , bufsize =- 1 , env = env , ) super () . __init__ ( * args , ** kwargs )","title":"__init__()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.collect","text":"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an error key, we log it as error (with the optional traceback value), and raise a CollectionError. If the dictionary values for keys loading_errors and parsing_errors are not empty, we log them as warnings. Then we pick up the only object within the objects list (there's always only one, because we collect them one by one), rebuild it's categories lists (see rebuild_category_lists() ), and return it. Parameters: Name Type Description Default identifier str The dotted-path of a Python object available in the Python path. required config dict Selection options, used to alter the data collection done by pytkdocs . required Exceptions: Type Description CollectionError When there was a problem collecting the object documentation. Returns: Type Description CollectorItem The collected object-tree. Source code in python/handler.py def collect ( self , identifier : str , config : dict ) -> CollectorItem : # noqa: WPS231 \"\"\"Collect the documentation tree given an identifier and selection options. In this method, we feed one line of JSON to the standard input of the subprocess that was opened during instantiation of the collector. Then we read one line of JSON on its standard output. We load back the JSON text into a Python dictionary. If there is a decoding error, we log it as error and raise a CollectionError. If the dictionary contains an `error` key, we log it as error (with the optional `traceback` value), and raise a CollectionError. If the dictionary values for keys `loading_errors` and `parsing_errors` are not empty, we log them as warnings. Then we pick up the only object within the `objects` list (there's always only one, because we collect them one by one), rebuild it's categories lists (see [`rebuild_category_lists()`][mkdocstrings_handlers.python.rendering.rebuild_category_lists]), and return it. Arguments: identifier: The dotted-path of a Python object available in the Python path. config: Selection options, used to alter the data collection done by `pytkdocs`. Raises: CollectionError: When there was a problem collecting the object documentation. Returns: The collected object-tree. \"\"\" final_config = {} for option in ( \"filters\" , \"members\" ): if option in config : final_config [ option ] = config [ option ] elif option in self . default_config : final_config [ option ] = self . default_config [ option ] logger . debug ( \"Preparing input\" ) json_input = json . dumps ({ \"objects\" : [{ \"path\" : identifier , ** final_config }]}) logger . debug ( \"Writing to process' stdin\" ) self . process . stdin . write ( json_input + \" \\n \" ) # type: ignore self . process . stdin . flush () # type: ignore logger . debug ( \"Reading process' stdout\" ) stdout = self . process . stdout . readline () # type: ignore logger . debug ( \"Loading JSON output as Python object\" ) try : result = json . loads ( stdout ) except json . decoder . JSONDecodeError as exception : error = \" \\n \" . join (( \"Error while loading JSON:\" , stdout , traceback . format_exc ())) raise CollectionError ( error ) from exception if \"error\" in result : error = result [ \"error\" ] if \"traceback\" in result : error += f \" \\n { result [ 'traceback' ] } \" raise CollectionError ( error ) for loading_error in result [ \"loading_errors\" ]: logger . warning ( loading_error ) for errors in result [ \"parsing_errors\" ] . values (): for parsing_error in errors : logger . warning ( parsing_error ) # We always collect only one object at a time result = result [ \"objects\" ][ 0 ] logger . debug ( \"Rebuilding categories and children lists\" ) rebuild_category_lists ( result ) return result","title":"collect()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.get_anchors","text":"Return the possible identifiers (HTML anchors) for a collected item. Parameters: Name Type Description Default data CollectorItem The collected data. required Returns: Type Description Sequence[str] The HTML anchors (without '#'), or an empty tuple if this item doesn't have an anchor. Source code in python/handler.py def get_anchors ( self , data : CollectorItem ) -> Sequence [ str ]: # noqa: D102 (ignore missing docstring) try : return ( data [ \"path\" ],) except KeyError : return ()","title":"get_anchors()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.load_inventory","text":"Yield items and their URLs from an inventory file streamed from in_file . This implements mkdocstrings' load_inventory \"protocol\" (see plugin.py). Parameters: Name Type Description Default in_file BinaryIO The binary file-like object to read the inventory from. required url str The URL that this file is being streamed from (used to guess base_url ). required base_url Optional[str] The URL that this inventory's sub-paths are relative to. None **kwargs Ignore additional arguments passed from the config. {} Yields: Type Description Iterator[Tuple[str, str]] Tuples of (item identifier, item URL). Source code in python/handler.py @classmethod def load_inventory ( cls , in_file : BinaryIO , url : str , base_url : Optional [ str ] = None , ** kwargs ) -> Iterator [ Tuple [ str , str ]]: \"\"\"Yield items and their URLs from an inventory file streamed from `in_file`. This implements mkdocstrings' `load_inventory` \"protocol\" (see plugin.py). Arguments: in_file: The binary file-like object to read the inventory from. url: The URL that this file is being streamed from (used to guess `base_url`). base_url: The URL that this inventory's sub-paths are relative to. **kwargs: Ignore additional arguments passed from the config. Yields: Tuples of (item identifier, item URL). \"\"\" if base_url is None : base_url = posixpath . dirname ( url ) for item in Inventory . parse_sphinx ( in_file , domain_filter = ( \"py\" ,)) . values (): # noqa: WPS526 yield item . name , posixpath . join ( base_url , item . uri )","title":"load_inventory()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.render","text":"Render a template using provided data and configuration options. Parameters: Name Type Description Default data CollectorItem The collected data to render. required config dict The rendering options. required Returns: Type Description str The rendered template as HTML. Source code in python/handler.py def render ( self , data : CollectorItem , config : dict ) -> str : # noqa: D102 (ignore missing docstring) final_config = ChainMap ( config , self . default_config ) template = self . env . get_template ( f \" { data [ 'category' ] } .html\" ) # Heading level is a \"state\" variable, that will change at each step # of the rendering recursion. Therefore, it's easier to use it as a plain value # than as an item in a dictionary. heading_level = final_config [ \"heading_level\" ] members_order = final_config [ \"members_order\" ] if members_order == \"alphabetical\" : sort_function = sort_key_alphabetical elif members_order == \"source\" : sort_function = sort_key_source else : raise PluginError ( f \"Unknown members_order ' { members_order } ', choose between 'alphabetical' and 'source'.\" ) sort_object ( data , sort_function = sort_function ) return template . render ( ** { \"config\" : final_config , data [ \"category\" ]: data , \"heading_level\" : heading_level , \"root\" : True }, )","title":"render()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.teardown","text":"Terminate the opened subprocess, set it to None . Source code in python/handler.py def teardown ( self ) -> None : \"\"\"Terminate the opened subprocess, set it to `None`.\"\"\" logger . debug ( \"Tearing process down\" ) self . process . terminate ()","title":"teardown()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.PythonHandler.update_env","text":"Update the Jinja environment. Parameters: Name Type Description Default md Markdown The Markdown instance. Useful to add functions able to convert Markdown into the environment filters. required config dict Configuration options for mkdocs and mkdocstrings , read from mkdocs.yml . See the source code of mkdocstrings.plugin.MkdocstringsPlugin.on_config to see what's in this dictionary. required Source code in python/handler.py def update_env ( self , md : Markdown , config : dict ) -> None : # noqa: D102 (ignore missing docstring) super () . update_env ( md , config ) self . env . trim_blocks = True self . env . lstrip_blocks = True self . env . keep_trailing_newline = False self . env . filters [ \"brief_xref\" ] = do_brief_xref","title":"update_env()"},{"location":"reference/mkdocstrings_handlers/python/handler/#mkdocstrings_handlers.python.handler.get_handler","text":"Simply return an instance of PythonHandler . Parameters: Name Type Description Default theme str The theme to use when rendering contents. required custom_templates Optional[str] Directory containing custom templates. None setup_commands Optional[List[str]] A list of commands as strings to be executed in the subprocess before pytkdocs . None config_file_path str | None The MkDocs configuration file path. None paths list[str] | None A list of paths to use as search paths. None config Any Configuration passed to the handler. {} Returns: Type Description PythonHandler An instance of PythonHandler . Source code in python/handler.py def get_handler ( theme : str , # noqa: W0613 (unused argument config) custom_templates : Optional [ str ] = None , setup_commands : Optional [ List [ str ]] = None , config_file_path : str | None = None , paths : list [ str ] | None = None , ** config : Any , ) -> PythonHandler : \"\"\"Simply return an instance of `PythonHandler`. Arguments: theme: The theme to use when rendering contents. custom_templates: Directory containing custom templates. setup_commands: A list of commands as strings to be executed in the subprocess before `pytkdocs`. config_file_path: The MkDocs configuration file path. paths: A list of paths to use as search paths. config: Configuration passed to the handler. Returns: An instance of `PythonHandler`. \"\"\" return PythonHandler ( handler = \"python\" , theme = theme , custom_templates = custom_templates , setup_commands = setup_commands , config_file_path = config_file_path , paths = paths , )","title":"get_handler()"},{"location":"reference/mkdocstrings_handlers/python/rendering/","text":"This module implements rendering utilities. do_brief_xref ( path ) \u00a4 Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/rendering.py def do_brief_xref ( path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief ) rebuild_category_lists ( obj ) \u00a4 Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/rendering.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child ) sort_key_alphabetical ( item ) \u00a4 Return an item's name or the final unicode character. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Name or final unicode character. Source code in python/rendering.py def sort_key_alphabetical ( item : CollectorItem ) -> Any : \"\"\"Return an item's name or the final unicode character. Arguments: item: A collected item. Returns: Name or final unicode character. \"\"\" # chr(sys.maxunicode) is a string that contains the final unicode # character, so if 'name' isn't found on the object, the item will go to # the end of the list. return item . get ( \"name\" , chr ( sys . maxunicode )) sort_key_source ( item ) \u00a4 Return an item's starting line number or -1. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Starting line number or -1. Source code in python/rendering.py def sort_key_source ( item : CollectorItem ) -> Any : \"\"\"Return an item's starting line number or -1. Arguments: item: A collected item. Returns: Starting line number or -1. \"\"\" # if 'line_start' isn't found on the object, the item will go to # the start of the list. return item . get ( \"source\" , {}) . get ( \"line_start\" , - 1 ) sort_object ( obj , sort_function ) \u00a4 Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj CollectorItem The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[CollectorItem], Any] The sort key function used to determine the order of elements. required Source code in python/rendering.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"rendering"},{"location":"reference/mkdocstrings_handlers/python/rendering/#mkdocstrings_handlers.python.rendering.do_brief_xref","text":"Filter to create cross-reference with brief text and full identifier as hover text. Parameters: Name Type Description Default path str The path to shorten and render. required Returns: Type Description Markup A span containing the brief cross-reference and the full one on hover. Source code in python/rendering.py def do_brief_xref ( path : str ) -> Markup : \"\"\"Filter to create cross-reference with brief text and full identifier as hover text. Arguments: path: The path to shorten and render. Returns: A span containing the brief cross-reference and the full one on hover. \"\"\" brief = path . split ( \".\" )[ - 1 ] return Markup ( \"<span data-autorefs-optional-hover= {path} > {brief} </span>\" ) . format ( path = path , brief = brief )","title":"do_brief_xref()"},{"location":"reference/mkdocstrings_handlers/python/rendering/#mkdocstrings_handlers.python.rendering.rebuild_category_lists","text":"Recursively rebuild the category lists of a collected object. Since pytkdocs dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a children list, containing all children, and another list for each category of children: attributes , classes , functions , methods and modules . It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the children list using their path. For each object, we recurse on every one of its children. Parameters: Name Type Description Default obj dict The collected object, loaded back from JSON into a Python dictionary. required Source code in python/rendering.py def rebuild_category_lists ( obj : dict ) -> None : \"\"\"Recursively rebuild the category lists of a collected object. Since `pytkdocs` dumps JSON on standard output, it must serialize the object-tree and flatten it to reduce data duplication and avoid cycle-references. Indeed, each node of the object-tree has a `children` list, containing all children, and another list for each category of children: `attributes`, `classes`, `functions`, `methods` and `modules`. It replaces the values in category lists with only the paths of the objects. Here, we reconstruct these category lists by picking objects in the `children` list using their path. For each object, we recurse on every one of its children. Arguments: obj: The collected object, loaded back from JSON into a Python dictionary. \"\"\" for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] = [ obj [ \"children\" ][ path ] for path in obj [ category ]] obj [ \"children\" ] = [ child for _ , child in obj [ \"children\" ] . items ()] for child in obj [ \"children\" ]: rebuild_category_lists ( child )","title":"rebuild_category_lists()"},{"location":"reference/mkdocstrings_handlers/python/rendering/#mkdocstrings_handlers.python.rendering.sort_key_alphabetical","text":"Return an item's name or the final unicode character. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Name or final unicode character. Source code in python/rendering.py def sort_key_alphabetical ( item : CollectorItem ) -> Any : \"\"\"Return an item's name or the final unicode character. Arguments: item: A collected item. Returns: Name or final unicode character. \"\"\" # chr(sys.maxunicode) is a string that contains the final unicode # character, so if 'name' isn't found on the object, the item will go to # the end of the list. return item . get ( \"name\" , chr ( sys . maxunicode ))","title":"sort_key_alphabetical()"},{"location":"reference/mkdocstrings_handlers/python/rendering/#mkdocstrings_handlers.python.rendering.sort_key_source","text":"Return an item's starting line number or -1. Parameters: Name Type Description Default item CollectorItem A collected item. required Returns: Type Description Any Starting line number or -1. Source code in python/rendering.py def sort_key_source ( item : CollectorItem ) -> Any : \"\"\"Return an item's starting line number or -1. Arguments: item: A collected item. Returns: Starting line number or -1. \"\"\" # if 'line_start' isn't found on the object, the item will go to # the start of the list. return item . get ( \"source\" , {}) . get ( \"line_start\" , - 1 )","title":"sort_key_source()"},{"location":"reference/mkdocstrings_handlers/python/rendering/#mkdocstrings_handlers.python.rendering.sort_object","text":"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Parameters: Name Type Description Default obj CollectorItem The collected object, as a dict. Note that this argument is mutated. required sort_function Callable[[CollectorItem], Any] The sort key function used to determine the order of elements. required Source code in python/rendering.py def sort_object ( obj : CollectorItem , sort_function : Callable [[ CollectorItem ], Any ]) -> None : \"\"\"Sort the collected object's children. Sorts the object's children list, then each category separately, and then recurses into each. Arguments: obj: The collected object, as a dict. Note that this argument is mutated. sort_function: The sort key function used to determine the order of elements. \"\"\" obj [ \"children\" ] . sort ( key = sort_function ) for category in ( \"attributes\" , \"classes\" , \"functions\" , \"methods\" , \"modules\" ): obj [ category ] . sort ( key = sort_function ) for child in obj [ \"children\" ]: sort_object ( child , sort_function = sort_function )","title":"sort_object()"},{"location":"coverage/","text":".md-content { max-width: none !important; } article h1, article > a { display: none; } var coviframe = document.getElementById(\"coviframe\"); function resizeIframe() { coviframe.style.height = coviframe.contentWindow.document.documentElement.offsetHeight + 'px'; } coviframe.contentWindow.document.body.onclick = function() { coviframe.contentWindow.location.reload(); }","title":"Coverage report"}]}